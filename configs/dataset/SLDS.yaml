# @package _global_

dataset:
  name: SLDS
  version: Debug
  ssm_params:
    Nlds: 3
    n_disc_states: 2
    latent_dim: 2
    obs_dim: 3
    random_projection: true
    rand_dim: 20
    partial_sup: true
    partial_obs: false
    full_sup: false
    overlap: 2
    normalize: true
    seed: 42
    time_bins_train: 200000
    time_bins_test: 50000
    z_timescale: [.975,.975,.975]

train:
  wandb_project: "TiDHy_eabe"
  device_id: null  # null = use all GPUs, int = specific GPU ID
  num_epochs: 1000
  sequence_length: 200
  overlap_factor: 10
  stack_inputs: true
  validation_cooldown: 25
  show_progress: true
  show_inf_progress: false
  test: false
  batch_size_input: true
  batch_size: null
  ##### Learning rates for different components #####
  # Multi-LR training
  use_schedule: true  # Enable learning rate scheduling
  schedule_transition_steps: 100  # Steps before applying decay
  schedule_decay: 0.96  # Learning rate decay factor
  learning_rate_s: 0.01  # Spatial decoder learning rate
  learning_rate_t: 0.01  # Temporal parameters learning rate  
  learning_rate_h: 0.001  # Hypernetwork learning rate
  # Single LR fallback (if multi-LR not specified)
  learning_rate: 1e-3
  lr_weights: 0.01  # GradNorm settings
  grad_norm: false  # Use GradNorm for loss balancing
  grad_alpha: 0.5
  weight_decay: 0.00001
  ##### Logging settings #####
  log_params_every: 10
  log_sparsity_every: 5

delay:
  delay_embed: false
  delay_tau: 3
  delay_pcs: true
  skipt: 15