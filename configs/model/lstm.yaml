# LSTM Baseline Model Configuration

##### Model Architecture #####
# Hidden dimension for LSTM (comparable to r_dim + r2_dim in TiDHy)
hidden_dim: 32

# Number of LSTM layers
num_layers: 1

# Dropout rate (0.0 = no dropout)
dropout_rate: 0.0

##### Loss Weights #####
# Weight for reconstruction loss (autoencoder task)
reconstruction_weight: 1.0

# Weight for next-step prediction loss
prediction_weight: 1.0

##### Checkpointing #####
# Maximum number of checkpoints to keep (0 = keep all)
checkpoint_max_to_keep: 5

##### Recording/Saving Results #####
# Save predictions and hidden states to HDF5 after training
save_results: false

# Which splits to save (if save_results=true)
save_train_results: false  # Train set (can be large)
save_val_results: true     # Validation set
save_test_results: true    # Test set

##### Notes #####
# For fair comparison with TiDHy:
# - Use hidden_dim comparable to r_dim + r2_dim (e.g., 16 + 8 = 24, or 32 + 16 = 48)
# - Can increase hidden_dim or num_layers to match TiDHy's parameter count
# - Dropout usually helps with overfitting, but start with 0.0 for baseline
