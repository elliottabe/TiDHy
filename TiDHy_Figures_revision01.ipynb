{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a0e1841-1962-46c0-a629-11e884c6c99c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd955540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-10-26 18:38:27,730:jax._src.xla_bridge:825: Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M3 Max\n",
      "\n",
      "systemMemory: 36.00 GB\n",
      "maxCacheSize: 14.04 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1761500307.731168 10921217 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1761500307.745534 10921217 service.cc:145] XLA service 0x103f6e380 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1761500307.745560 10921217 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1761500307.746913 10921217 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1761500307.746921 10921217 mps_client.cc:384] XLA backend will use up to 30150197248 bytes on device 0 for SimpleAllocator.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "try:\n",
    "    import blackjax\n",
    "except ModuleNotFoundError:\n",
    "    print('installing blackjax')\n",
    "    %pip install -qq blackjax\n",
    "    import blackjax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from functools import partial\n",
    "import jax \n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "from jax import random as  jr\n",
    "from jax import numpy as jnp\n",
    "from jax import jit, vmap\n",
    "from itertools import count\n",
    "\n",
    "from dynamax.linear_gaussian_ssm import LinearGaussianConjugateSSM\n",
    "from dynamax.parameters import log_det_jac_constrain, to_unconstrained, from_unconstrained\n",
    "from dynamax.utils.utils import random_rotation, pytree_stack, pytree_slice, ensure_array_has_batch_dim\n",
    "\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf35205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TiDHy.utils import io_dict_to_hdf5 as ioh5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014eaebf-52c1-4b95-a6d9-34a1b1525b1b",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# # %load_ext autoreload\n",
    "# # %autoreload 2\n",
    "# import sys\n",
    "# import os.path as op\n",
    "# # import ssm\n",
    "# import itertools\n",
    "# # import autograd.numpy as np\n",
    "# import matplotlib.pyplot as pltx\n",
    "# import matplotlib.gridspec as gridspec\n",
    "# import seaborn as sns\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # np.set_printoptions(suppress=True)\n",
    "\n",
    "# # import torch\n",
    "# # import torch.optim as optim\n",
    "# # from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# from tqdm.auto import tqdm\n",
    "# from pathlib import Path\n",
    "# from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# # import TiDHy\n",
    "# # from TiDHy.utils.utils import *\n",
    "# from TiDHy.datasets import load_dataset\n",
    "# import TiDHy.utils.io_dict_to_hdf5 as ioh5\n",
    "# from TiDHy.Evaluate_TiDHy import run_seq_len_model\n",
    "\n",
    "# ##### Plotting settings ######\n",
    "# import matplotlib as mpl\n",
    "# mpl.rcParams.update({'font.size':          10,\n",
    "#                      'axes.linewidth':     2,\n",
    "#                      'xtick.major.size':   5,\n",
    "#                      'ytick.major.size':   5,\n",
    "#                      'xtick.major.width':  2,\n",
    "#                      'ytick.major.width':  2,\n",
    "#                      'axes.spines.right':  False,\n",
    "#                      'axes.spines.top':    False,\n",
    "#                      'pdf.fonttype':       42,\n",
    "#                      'ps.fonttype':        42,\n",
    "#                      'xtick.labelsize':    10,\n",
    "#                      'ytick.labelsize':    10,\n",
    "#                      'figure.facecolor':   'white',\n",
    "#                      'pdf.use14corefonts': True,\n",
    "#                      'font.family':        'sans-serif',\n",
    "#                     #  'font.family':        'Arial',\n",
    "#                     #  'font.sans-serif':    'Arial',\n",
    "#                      'font.serif':         'Arial',\n",
    "#                     })\n",
    "\n",
    "# from matplotlib.colors import ListedColormap\n",
    "# clrs = ['#1A237E','#7E57C2','#757575','#BDBDBD','#4CAF50','#FF9800','#795548','#FF4081','#00BCD4','#FF1744','#FFFFFF','#000000']\n",
    "# cmap = ListedColormap(clrs)\n",
    "\n",
    "# # device = torch.device(0) #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df481e9",
   "metadata": {},
   "source": [
    "# Load SLDS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f0f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 2\n",
    "emission_dim = 10\n",
    "num_timesteps = 100\n",
    "k1, k2, k3 = jr.split(jr.PRNGKey(0), 3)\n",
    "\n",
    "# Construct the true model with randomly initialized parameters\n",
    "true_A = 0.99 * random_rotation(seed=k1, n=state_dim, theta=jnp.pi / 10)\n",
    "true_Sigma = 0.01 * jnp.eye(state_dim)\n",
    "true_model = LinearGaussianConjugateSSM(state_dim, emission_dim)\n",
    "true_params, param_props = true_model.initialize(\n",
    "    key=k1, dynamics_weights=true_A, dynamics_covariance=true_Sigma)            \n",
    "\n",
    "# Sample states and emissions from the true model\n",
    "true_states, emissions = true_model.sample(true_params, k3, num_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78001d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import nnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c4c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TiDHy.models.TiDHy_nnx import TiDHy\n",
    "from TiDHy.models.TiDHy_nnx_training import create_optimizer, train_step\n",
    "from TiDHy.models.TiDHy_nnx_example import example_manual_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009e0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dim = 16\n",
    "r2_dim = 8\n",
    "mix_dim = 8\n",
    "input_dim = 9\n",
    "hyper_hid_dim = 32\n",
    "T_wind = 20\n",
    "rngs = nnx.Rngs(params=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65230d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TiDHy(r_dim=r_dim,\n",
    "              r2_dim=r2_dim,\n",
    "              mix_dim=mix_dim,\n",
    "              input_dim=input_dim,\n",
    "              hyper_hid_dim=hyper_hid_dim,\n",
    "              rngs=rngs,\n",
    "              show_inf_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda16cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = ioh5.load('/Users/eabe/Research/data/hypernets/SLDS/datasets/SLDS_N3_zD2_xD2_yD3_seed42.h5',enable_jax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deebac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = data_dict['inputs_train'].reshape(data_dict['inputs_train'].shape[0]//T_wind,T_wind,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4239953d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ccf831e83448078ca2a9213ccf5f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = model(inputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ba3a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(spatial_loss_rhat, spatial_loss_rbar, temp_loss, r2_losses, r_first, r2) = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef455054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Example 3: Manual Training Loop\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model, optimizer = \u001b[43mexample_manual_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/MyRepos/TiDHy/TiDHy/models/TiDHy_nnx_example.py:15\u001b[39m, in \u001b[36mexample_manual_training\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjnp\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mflax\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nnx\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTiDHy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mTiDHy_nnx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TiDHy\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTiDHy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mTiDHy_nnx_training\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     train_model,\n\u001b[32m     18\u001b[39m     train_step,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     create_optimizer\n\u001b[32m     26\u001b[39m )\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexample_basic_usage\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/MyRepos/TiDHy/TiDHy/models/TiDHy_nnx_training.py:74\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, optimizer, X)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss, {\n\u001b[32m     67\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mspatial_loss_rhat\u001b[39m\u001b[33m'\u001b[39m: spatial_loss_rhat,\n\u001b[32m     68\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mspatial_loss_rbar\u001b[39m\u001b[33m'\u001b[39m: spatial_loss_rbar,\n\u001b[32m     69\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtemp_loss\u001b[39m\u001b[33m'\u001b[39m: temp_loss,\n\u001b[32m     70\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mr2_losses\u001b[39m\u001b[33m'\u001b[39m: r2_losses\n\u001b[32m     71\u001b[39m     }\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m (loss, metrics), grads = \u001b[43mnnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[32m     77\u001b[39m optimizer.update(grads)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/flax/nnx/graph.py:2060\u001b[39m, in \u001b[36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2057\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m   2058\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_context_manager_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m   2059\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2060\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/flax/nnx/transforms/autodiff.py:163\u001b[39m, in \u001b[36m_grad_general.<locals>.grad_wrapper\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    151\u001b[39m pure_args = extract.to_tree(\n\u001b[32m    152\u001b[39m   args, prefix=arg_filters, split_fn=_grad_split_fn, ctxtag=\u001b[33m'\u001b[39m\u001b[33mgrad\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    153\u001b[39m )\n\u001b[32m    155\u001b[39m gradded_fn = transform(\n\u001b[32m    156\u001b[39m   GradFn(f, has_aux, nondiff_states),\n\u001b[32m    157\u001b[39m   argnums=jax_argnums,\n\u001b[32m   (...)\u001b[39m\u001b[32m    160\u001b[39m   allow_int=allow_int,\n\u001b[32m    161\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m fn_out = \u001b[43mgradded_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpure_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_grads\u001b[39m(grads):\n\u001b[32m    166\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m jax.tree.map(\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x.state \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, extract.NodeStates) \u001b[38;5;28;01melse\u001b[39;00m x,\n\u001b[32m    168\u001b[39m     grads,\n\u001b[32m    169\u001b[39m     is_leaf=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, extract.NodeStates),\n\u001b[32m    170\u001b[39m   )\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/api.py:512\u001b[39m, in \u001b[36mvalue_and_grad.<locals>.value_and_grad_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    510\u001b[39m   ans, vjp_py = _vjp(f_partial, *dyn_args)\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m   ans, vjp_py, aux = \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mdyn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m _check_scalar(ans)\n\u001b[32m    514\u001b[39m tree_map(partial(_check_output_dtype_grad, holomorphic), ans)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/api.py:2183\u001b[39m, in \u001b[36m_vjp\u001b[39m\u001b[34m(fun, has_aux, *primals)\u001b[39m\n\u001b[32m   2181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2182\u001b[39m   flat_fun, out_aux_trees = flatten_fun_nokwargs2(fun, in_tree)\n\u001b[32m-> \u001b[39m\u001b[32m2183\u001b[39m   out_primals, vjp, aux = \u001b[43mad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2184\u001b[39m   out_tree, aux_tree = out_aux_trees()\n\u001b[32m   2185\u001b[39m out_primal_avals = \u001b[38;5;28mmap\u001b[39m(shaped_abstractify, out_primals)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:294\u001b[39m, in \u001b[36mvjp\u001b[39m\u001b[34m(traceable, primals, has_aux)\u001b[39m\n\u001b[32m    292\u001b[39m   out_primals, pvals, jaxpr, consts = linearize(traceable, *primals)\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   out_primals, pvals, jaxpr, consts, aux = \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munbound_vjp\u001b[39m(pvals, jaxpr, consts, *cts):\n\u001b[32m    297\u001b[39m   cts = \u001b[38;5;28mtuple\u001b[39m(ct \u001b[38;5;28;01mfor\u001b[39;00m ct, pval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cts, pvals) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pval.is_known())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:277\u001b[39m, in \u001b[36mlinearize\u001b[39m\u001b[34m(traceable, *primals, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m _, in_tree = tree_flatten(((primals, primals), {}))\n\u001b[32m    276\u001b[39m jvpfun_flat, out_tree = flatten_fun(jvpfun, in_tree)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m jaxpr, out_pvals, consts = \u001b[43mpe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m out_primals_pvals, out_tangents_pvals = tree_unflatten(out_tree(), out_pvals)\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m out_primal_pval.is_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/profiler.py:354\u001b[39m, in \u001b[36mannotate_function.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    353\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, **decorator_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:614\u001b[39m, in \u001b[36mtrace_to_jaxpr_nounits\u001b[39m\u001b[34m(fun, pvals, instantiate)\u001b[39m\n\u001b[32m    612\u001b[39m fun = trace_to_subjaxpr_nounits(fun, trace, instantiate, fun.debug_info)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m core.set_current_trace(trace):\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m   jaxpr, (out_pvals, consts, env) = \u001b[43mfun\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    615\u001b[39m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m trace, fun\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/linear_util.py:211\u001b[39m, in \u001b[36mWrappedFun.call_wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    210\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:628\u001b[39m, in \u001b[36mtrace_to_subjaxpr_nounits\u001b[39m\u001b[34m(f, trace, instantiate, debug_info, in_pvals)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;129m@lu\u001b[39m.transformation2\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrace_to_subjaxpr_nounits\u001b[39m(\n\u001b[32m    622\u001b[39m     f: Callable,\n\u001b[32m   (...)\u001b[39m\u001b[32m    625\u001b[39m     debug_info: core.DebugInfo,\n\u001b[32m    626\u001b[39m     in_pvals: Sequence[PartialVal]):\n\u001b[32m    627\u001b[39m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(pv, PartialVal) \u001b[38;5;28;01mfor\u001b[39;00m pv \u001b[38;5;129;01min\u001b[39;00m in_pvals), in_pvals\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m   out_tracers, jaxpr, out_consts, env = \u001b[43m_trace_to_subjaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m      \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstantiate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m   out_pvals = [t.pval \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m out_tracers]\n\u001b[32m    631\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m out_tracers\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:661\u001b[39m, in \u001b[36m_trace_to_subjaxpr_nounits\u001b[39m\u001b[34m(f, trace, instantiate, in_pvals, debug_info)\u001b[39m\n\u001b[32m    659\u001b[39m in_args = merge_lists(in_knowns, in_tracers, in_consts)\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m core.set_current_trace(trace):\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m   ans = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43min_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ans, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)), (\n\u001b[32m    663\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, core.Tracer) \u001b[38;5;129;01mor\u001b[39;00m core.valid_jaxtype(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ans), (\n\u001b[32m    665\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/api_util.py:73\u001b[39m, in \u001b[36mflatten_fun\u001b[39m\u001b[34m(f, store, in_tree, *args_flat)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;129m@lu\u001b[39m.transformation_with_aux2\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflatten_fun\u001b[39m(f: Callable, store: lu.Store,\n\u001b[32m     71\u001b[39m                 in_tree: PyTreeDef, *args_flat):\n\u001b[32m     72\u001b[39m   py_args, py_kwargs = tree_unflatten(in_tree, args_flat)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m   ans = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m   ans, out_tree = tree_flatten(ans)\n\u001b[32m     75\u001b[39m   store.store(out_tree)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:81\u001b[39m, in \u001b[36mjvpfun\u001b[39m\u001b[34m(f, instantiate, transform_stack, primals, tangents)\u001b[39m\n\u001b[32m     78\u001b[39m ctx = (source_info_util.transform_name_stack(\u001b[33m'\u001b[39m\u001b[33mjvp\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m transform_stack\n\u001b[32m     79\u001b[39m        \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext())\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m   out_primals, out_tangents = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(instantiate) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m     83\u001b[39m   instantiate = [instantiate] * \u001b[38;5;28mlen\u001b[39m(out_tangents)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:145\u001b[39m, in \u001b[36mjvp_subtrace_aux\u001b[39m\u001b[34m(f, store, tag, primals, tangents)\u001b[39m\n\u001b[32m    143\u001b[39m trace = JVPTrace(parent_trace, tag)\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m core.set_current_trace(trace):\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m   ans, aux = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_jvp_tracer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m out_primals, out_tangents = unzip2(\u001b[38;5;28mmap\u001b[39m(trace.to_primal_tangent_pair, ans))\n\u001b[32m    147\u001b[39m aux_primals = [x.primal \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, JVPTracer) \u001b[38;5;129;01mand\u001b[39;00m x._trace.tag \u001b[38;5;129;01mis\u001b[39;00m tag\n\u001b[32m    148\u001b[39m                \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m aux]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/api_util.py:106\u001b[39m, in \u001b[36mflatten_fun_nokwargs2\u001b[39m\u001b[34m(f, store, in_tree, *args_flat)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;129m@lu\u001b[39m.transformation_with_aux2\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflatten_fun_nokwargs2\u001b[39m(f, store, in_tree, *args_flat):\n\u001b[32m    105\u001b[39m   py_args = tree_unflatten(in_tree, args_flat)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m   pair = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpy_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pair, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pair) != \u001b[32m2\u001b[39m:\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mexpected function with aux output to return a two-element \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtuple, but got type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/api_util.py:288\u001b[39m, in \u001b[36m_argnums_partial\u001b[39m\u001b[34m(_fun, _dyn_argnums, _fixed_args, *dyn_args, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m args = [\u001b[38;5;28mnext\u001b[39m(fixed_args_).val \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m sentinel \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(fixed_args_, sentinel) \u001b[38;5;129;01mis\u001b[39;00m sentinel\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/linear_util.py:396\u001b[39m, in \u001b[36m_get_result_paths_thunk\u001b[39m\u001b[34m(_fun, _store, *args, **kwargs)\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m   ans = \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m   result_paths = \u001b[38;5;28mtuple\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_clean_keystr_arg_names(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans))\n\u001b[32m    398\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[32m    399\u001b[39m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[32m    400\u001b[39m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/flax/nnx/transforms/autodiff.py:88\u001b[39m, in \u001b[36mGradFn.__call__\u001b[39m\u001b[34m(self, *pure_args)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ctx.merge(value.graphdef, value.state, nondiff)\n\u001b[32m     84\u001b[39m args = extract.from_tree(\n\u001b[32m     85\u001b[39m   pure_args, merge_fn=_grad_merge_fn, ctxtag=\u001b[33m'\u001b[39m\u001b[33mgrad\u001b[39m\u001b[33m'\u001b[39m, is_inner=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     86\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m args_out = extract.clear_non_graph_nodes(args)\n\u001b[32m     91\u001b[39m pure_args_out, pure_out = extract.to_tree((args_out, out), ctxtag=\u001b[33m'\u001b[39m\u001b[33mgrad\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/MyRepos/TiDHy/TiDHy/models/TiDHy_nnx_training.py:59\u001b[39m, in \u001b[36mtrain_step.<locals>.loss_fn\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_fn\u001b[39m(model: TiDHy):\n\u001b[32m     58\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute loss for training\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     spatial_loss_rhat, spatial_loss_rbar, temp_loss, r2_losses, _, _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     total_loss = spatial_loss_rhat + spatial_loss_rbar + temp_loss\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model.use_r2_decoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/MyRepos/TiDHy/TiDHy/models/TiDHy_nnx.py:449\u001b[39m, in \u001b[36mTiDHy.__call__\u001b[39m\u001b[34m(self, X, training)\u001b[39m\n\u001b[32m    446\u001b[39m r2_p = r2.copy()\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m# Inference step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m r, r2, r2_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[32m    452\u001b[39m x_hat = \u001b[38;5;28mself\u001b[39m.spatial_decoder(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/MyRepos/TiDHy/TiDHy/models/TiDHy_nnx.py:561\u001b[39m, in \u001b[36mTiDHy.inf\u001b[39m\u001b[34m(self, x, r_p, r2)\u001b[39m\n\u001b[32m    558\u001b[39m r2 = optax.apply_updates(r2, updates_r2)\n\u001b[32m    560\u001b[39m \u001b[38;5;66;03m# Apply soft thresholding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m r = \u001b[43msoft_thresholding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlmda_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    562\u001b[39m r2 = soft_thresholding(r2, \u001b[38;5;28mself\u001b[39m.lmda_r2)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Check convergence\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/MyRepos/TiDHy/TiDHy/models/TiDHy_nnx.py:19\u001b[39m, in \u001b[36msoft_thresholding\u001b[39m\u001b[34m(r, lmda)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msoft_thresholding\u001b[39m(r: jax.Array, lmda: \u001b[38;5;28mfloat\u001b[39m) -> jax.Array:\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Non-negative proximal gradient for L1 regularization.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mlmda\u001b[49m\u001b[43m)\u001b[49m * jnp.sign(r)\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/custom_derivatives.py:302\u001b[39m, in \u001b[36mcustom_jvp.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    299\u001b[39m flat_fun, out_type1 = _flatten_fun_nokwargs(f_, in_tree)\n\u001b[32m    300\u001b[39m flat_jvp, out_type2 = _flatten_jvp(jvp, primal_name, debug_jvp.func_name,\n\u001b[32m    301\u001b[39m                                    in_tree, out_type1)\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m out_flat = \u001b[43mcustom_jvp_call_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_jvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43msymbolic_zeros\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msymbolic_zeros\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m _, (out_tree, _, _) = lu.merge_linear_aux(out_type1, out_type2)\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, out_flat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/custom_derivatives.py:390\u001b[39m, in \u001b[36mCustomJVPCallPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/core.py:552\u001b[39m, in \u001b[36mPrimitive._true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    550\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    554\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/custom_derivatives.py:394\u001b[39m, in \u001b[36mCustomJVPCallPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[32m    393\u001b[39m   fun, jvp, tracers = args[\u001b[32m0\u001b[39m], args[\u001b[32m1\u001b[39m], args[\u001b[32m2\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_custom_jvp_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:557\u001b[39m, in \u001b[36mJVPTrace.process_custom_jvp_call\u001b[39m\u001b[34m(self, prim, fun, f_jvp, tracers, symbolic_zeros)\u001b[39m\n\u001b[32m    555\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    556\u001b[39m     tangents_in = \u001b[38;5;28mmap\u001b[39m(replace_internal_symbolic_zeros, tangents_in)\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m   outs = \u001b[43mf_jvp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprimals_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtangents_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m primals_out, tangents_out = split_list(outs, [\u001b[38;5;28mlen\u001b[39m(outs) // \u001b[32m2\u001b[39m])\n\u001b[32m    560\u001b[39m tangents_out = \u001b[38;5;28mmap\u001b[39m(replace_rule_output_symbolic_zeros, tangents_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/linear_util.py:211\u001b[39m, in \u001b[36mWrappedFun.call_wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    210\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/custom_derivatives.py:312\u001b[39m, in \u001b[36m_flatten_jvp\u001b[39m\u001b[34m(f, store, primal_name, jvp_name, in_tree, maybe_out_type, *args)\u001b[39m\n\u001b[32m    310\u001b[39m py_primals = tree_unflatten(in_tree, primals_in)\n\u001b[32m    311\u001b[39m py_tangents = tree_unflatten(in_tree, tangents_in)\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m pair_out = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpy_primals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpy_tangents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pair_out, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pair_out) != \u001b[32m2\u001b[39m:\n\u001b[32m    314\u001b[39m   msg = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCustom JVP rule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjvp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprimal_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    315\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mmust produce a pair (list or tuple of length two) representing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    316\u001b[39m          \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprimal and tangent outputs, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/linear_util.py:396\u001b[39m, in \u001b[36m_get_result_paths_thunk\u001b[39m\u001b[34m(_fun, _store, *args, **kwargs)\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m   ans = \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m   result_paths = \u001b[38;5;28mtuple\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_clean_keystr_arg_names(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans))\n\u001b[32m    398\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[32m    399\u001b[39m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[32m    400\u001b[39m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/custom_derivatives.py:250\u001b[39m, in \u001b[36mcustom_jvp.defjvps.<locals>.jvp\u001b[39m\u001b[34m(primals, tangents)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjvp\u001b[39m(primals, tangents):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m   primal_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m   zeros = _zeros_like_pytree(primal_out)\n\u001b[32m    252\u001b[39m   all_tangents_out = [jvp(t, primal_out, *primals) \u001b[38;5;28;01mif\u001b[39;00m jvp \u001b[38;5;28;01melse\u001b[39;00m zeros\n\u001b[32m    253\u001b[39m                       \u001b[38;5;28;01mfor\u001b[39;00m t, jvp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tangents, jvps)]\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/custom_derivatives.py:261\u001b[39m, in \u001b[36mcustom_jvp.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;129m@traceback_util\u001b[39m.api_boundary\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ReturnValue:  \u001b[38;5;66;03m# pytype: disable=invalid-annotation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m   debug = \u001b[43mdebug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcustom_jvp fun\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mstatic_argnums\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnondiff_argnums\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m   primal_name = debug.func_name\n\u001b[32m    264\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jvp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/api_util.py:618\u001b[39m, in \u001b[36mdebug_info\u001b[39m\u001b[34m(traced_for, fun, args, kwargs, static_argnums, static_argnames, result_paths_thunk, sourceinfo, signature)\u001b[39m\n\u001b[32m    616\u001b[39m   sourceinfo = fun_sourceinfo(fun)\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m   signature = \u001b[43mfun_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    619\u001b[39m arg_names = _non_static_arg_names(signature, args, kwargs, static_argnums,\n\u001b[32m    620\u001b[39m                                   static_argnames)\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m core.DebugInfo(traced_for, sourceinfo, arg_names, result_paths_thunk)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/site-packages/jax/_src/api_util.py:626\u001b[39m, in \u001b[36mfun_signature\u001b[39m\u001b[34m(fun)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfun_signature\u001b[39m(fun: Callable) -> inspect.Signature | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    625\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minspect\u001b[49m\u001b[43m.\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    627\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    628\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:3263\u001b[39m, in \u001b[36msignature\u001b[39m\u001b[34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[39m\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msignature\u001b[39m(obj, *, follow_wrapped=\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, eval_str=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   3262\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3264\u001b[39m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:3011\u001b[39m, in \u001b[36mSignature.from_callable\u001b[39m\u001b[34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[39m\n\u001b[32m   3007\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   3008\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, *,\n\u001b[32m   3009\u001b[39m                   follow_wrapped=\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, eval_str=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   3010\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3011\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3012\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3013\u001b[39m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:2472\u001b[39m, in \u001b[36m_signature_from_callable\u001b[39m\u001b[34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[39m\n\u001b[32m   2468\u001b[39m \u001b[38;5;66;03m# Was this function wrapped by a decorator?\u001b[39;00m\n\u001b[32m   2469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_wrapper_chains:\n\u001b[32m   2470\u001b[39m     \u001b[38;5;66;03m# Unwrap until we find an explicit signature or a MethodType (which will be\u001b[39;00m\n\u001b[32m   2471\u001b[39m     \u001b[38;5;66;03m# handled explicitly below).\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2472\u001b[39m     obj = \u001b[43munwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m__signature__\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMethodType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types.MethodType):\n\u001b[32m   2475\u001b[39m         \u001b[38;5;66;03m# If the unwrapped object is a *method*, we might want to\u001b[39;00m\n\u001b[32m   2476\u001b[39m         \u001b[38;5;66;03m# skip its first parameter (self).\u001b[39;00m\n\u001b[32m   2477\u001b[39m         \u001b[38;5;66;03m# See test_signature_wrapped_bound_method for details.\u001b[39;00m\n\u001b[32m   2478\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _get_signature_of(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:757\u001b[39m, in \u001b[36munwrap\u001b[39m\u001b[34m(func, stop)\u001b[39m\n\u001b[32m    755\u001b[39m recursion_limit = sys.getrecursionlimit()\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[33m'\u001b[39m\u001b[33m__wrapped__\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    758\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    759\u001b[39m     func = func.__wrapped__\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:2472\u001b[39m, in \u001b[36m_signature_from_callable.<locals>.<lambda>\u001b[39m\u001b[34m(f)\u001b[39m\n\u001b[32m   2468\u001b[39m \u001b[38;5;66;03m# Was this function wrapped by a decorator?\u001b[39;00m\n\u001b[32m   2469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_wrapper_chains:\n\u001b[32m   2470\u001b[39m     \u001b[38;5;66;03m# Unwrap until we find an explicit signature or a MethodType (which will be\u001b[39;00m\n\u001b[32m   2471\u001b[39m     \u001b[38;5;66;03m# handled explicitly below).\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2472\u001b[39m     obj = unwrap(obj, stop=(\u001b[38;5;28;01mlambda\u001b[39;00m f: \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[33m\"\u001b[39m\u001b[33m__signature__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2473\u001b[39m                             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, types.MethodType)))\n\u001b[32m   2474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types.MethodType):\n\u001b[32m   2475\u001b[39m         \u001b[38;5;66;03m# If the unwrapped object is a *method*, we might want to\u001b[39;00m\n\u001b[32m   2476\u001b[39m         \u001b[38;5;66;03m# skip its first parameter (self).\u001b[39;00m\n\u001b[32m   2477\u001b[39m         \u001b[38;5;66;03m# See test_signature_wrapped_bound_method for details.\u001b[39;00m\n\u001b[32m   2478\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _get_signature_of(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:3263\u001b[39m, in \u001b[36msignature\u001b[39m\u001b[34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[39m\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msignature\u001b[39m(obj, *, follow_wrapped=\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, eval_str=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   3262\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3264\u001b[39m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:3011\u001b[39m, in \u001b[36mSignature.from_callable\u001b[39m\u001b[34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[39m\n\u001b[32m   3007\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   3008\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, *,\n\u001b[32m   3009\u001b[39m                   follow_wrapped=\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, eval_str=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   3010\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3011\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3012\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3013\u001b[39m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:2523\u001b[39m, in \u001b[36m_signature_from_callable\u001b[39m\u001b[34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[39m\n\u001b[32m   2518\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m sig.replace(parameters=new_params)\n\u001b[32m   2520\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[32m   2521\u001b[39m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[32m   2522\u001b[39m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2524\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2525\u001b[39m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[32m   2528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[32m   2529\u001b[39m                                    skip_bound_arg=skip_bound_arg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:2421\u001b[39m, in \u001b[36m_signature_from_function\u001b[39m\u001b[34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[39m\n\u001b[32m   2416\u001b[39m     parameters.append(Parameter(name, annotation=annotation,\n\u001b[32m   2417\u001b[39m                                 kind=_VAR_KEYWORD))\n\u001b[32m   2419\u001b[39m \u001b[38;5;66;03m# Is 'func' is a pure Python function - don't validate the\u001b[39;00m\n\u001b[32m   2420\u001b[39m \u001b[38;5;66;03m# parameters list (for correct order and defaults), it should be OK.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2422\u001b[39m \u001b[43m           \u001b[49m\u001b[43mreturn_annotation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreturn\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_empty\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2423\u001b[39m \u001b[43m           \u001b[49m\u001b[43m__validate_parameters__\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_duck_function\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:3002\u001b[39m, in \u001b[36mSignature.__init__\u001b[39m\u001b[34m(self, parameters, return_annotation, __validate_parameters__)\u001b[39m\n\u001b[32m   3000\u001b[39m             params[name] = param\n\u001b[32m   3001\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3002\u001b[39m         params = \u001b[43mOrderedDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3004\u001b[39m \u001b[38;5;28mself\u001b[39m._parameters = types.MappingProxyType(params)\n\u001b[32m   3005\u001b[39m \u001b[38;5;28mself\u001b[39m._return_annotation = return_annotation\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:3002\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   3000\u001b[39m             params[name] = param\n\u001b[32m   3001\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3002\u001b[39m         params = OrderedDict((\u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m, param) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m parameters)\n\u001b[32m   3004\u001b[39m \u001b[38;5;28mself\u001b[39m._parameters = types.MappingProxyType(params)\n\u001b[32m   3005\u001b[39m \u001b[38;5;28mself\u001b[39m._return_annotation = return_annotation\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TiDHy/lib/python3.11/inspect.py:2722\u001b[39m, in \u001b[36mParameter.name\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2719\u001b[39m     \u001b[38;5;28mself\u001b[39m._default = state[\u001b[33m'\u001b[39m\u001b[33m_default\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m   2720\u001b[39m     \u001b[38;5;28mself\u001b[39m._annotation = state[\u001b[33m'\u001b[39m\u001b[33m_annotation\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m2722\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   2723\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mname\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   2724\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._name\n\u001b[32m   2726\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   2727\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model, optimizer = example_manual_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7da2f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /data/users/eabe/hypernets/SLDS/TiDHy_SLDS/r2_orth_long/Orth_alpha_r2=5,dataset.ssm_params.seed=10,dataset.train.num_epochs=1500/config.yaml\n",
      "1 /data/users/eabe/hypernets/SLDS/TiDHy_SLDS/r2_orth_long/Orth_alpha_r2=5,dataset.ssm_params.seed=11,dataset.train.num_epochs=1500/config.yaml\n",
      "2 /data/users/eabe/hypernets/SLDS/TiDHy_SLDS/r2_orth_long/Orth_alpha_r2=5,dataset.ssm_params.seed=12,dataset.train.num_epochs=1500/config.yaml\n",
      "3 /data/users/eabe/hypernets/SLDS/TiDHy_SLDS/r2_orth_long/Orth_alpha_r2=5,dataset.ssm_params.seed=13,dataset.train.num_epochs=1500/config.yaml\n",
      "4 /data/users/eabe/hypernets/SLDS/TiDHy_SLDS/r2_orth_long/Orth_alpha_r2=5,dataset.ssm_params.seed=14,dataset.train.num_epochs=1500/config.yaml\n",
      "5 /data/users/eabe/hypernets/SLDS/TiDHy_SLDS/r2_orth_long/Orth_alpha_r2=5,dataset.ssm_params.seed=15,dataset.train.num_epochs=1500/config.yaml\n",
      "6 /data/users/eabe/hypernets/SLDS/TiDHy_SLDS/r2_orth_long/Orth_alpha_r2=5,dataset.ssm_params.seed=16,dataset.train.num_epochs=1500/config.yaml\n",
      "7 /data/users/eabe/hypernets/SLDS/TiDHy_SLDS/r2_orth_long/Orth_alpha_r2=5,dataset.ssm_params.seed=17,dataset.train.num_epochs=1500/config.yaml\n"
     ]
    }
   ],
   "source": [
    "dataset = 'SLDS'\n",
    "version = 'r2_orth_long'\n",
    "# version = 'partial_obs'\n",
    "base_dir = Path('/data/users/eabe/hypernets/{}/TiDHy_{}/{}'.format(dataset,dataset,version))\n",
    "configs = sorted(list(base_dir.rglob('*config.yaml'))[::2])\n",
    "fig_path = Path('/data/users/eabe/hypernets/SLDS/TiDHy_SLDS/r2_orth_long/Paper_Figs')\n",
    "for n,conf in enumerate(configs):\n",
    "    print(n,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97fe884c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "cfg_path =configs[n]# \n",
    "default_model_config = '/home/eabe/Research/MyRepos/TiDHy/conf/dataset/model/default_model.yaml'\n",
    "cfg = load_cfg(cfg_path, default_model_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "280b7c65",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataset: SLDS\n",
      "Setting seed: 10\n",
      "Setting seed: 10\n",
      "Setting seed: 10\n",
      "x Timescales: {'0': -0.025, '1': -0.25, '2': -0.1, '3': -0.5, '4': -0.01, '5': -0.75}, z Timescales: [0.975, 0.975, 0.975]\n",
      "Our inputs have shape: torch.Size([250, 200, 20])\n"
     ]
    }
   ],
   "source": [
    "data_dict, cfg = load_dataset(cfg)\n",
    "\n",
    "# ##### Convert to float tensors #####\n",
    "train_inputs = torch.tensor(data_dict['inputs_train']).float()\n",
    "test_inputs = torch.tensor(data_dict['inputs_test']).float()\n",
    "val_inputs = torch.tensor(data_dict['inputs_val']).float()\n",
    "\n",
    "input_dim = test_inputs.shape[-1]\n",
    "# test_inputs = test_inputs.unsqueeze(0)\n",
    "# test_inputs = stack_data(test_inputs,cfg.train.sequence_length,overlap=cfg.train.sequence_length//cfg.train.overlap_factor)\n",
    "test_inputs = test_inputs.reshape(-1, cfg.train.sequence_length, input_dim)\n",
    "val_inputs = val_inputs.reshape(-1, cfg.train.sequence_length, input_dim)\n",
    "# train_inputs = train_inputs.reshape(-1, cfg.train.sequence_length, input_dim)\n",
    "# cfg.model.input_dim = input_dim\n",
    "\n",
    "\n",
    "\n",
    "print(f'Our inputs have shape: {test_inputs.shape}')\n",
    "cfg.model.input_dim = input_dim\n",
    "test_dataset = torch.utils.data.TensorDataset(test_inputs)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_inputs)\n",
    "val_dataset = torch.utils.data.TensorDataset(val_inputs)\n",
    "# dataloader_train = torch.utils.data.DataLoader(train_dataset,batch_size=train_inputs.shape[0],pin_memory=True,shuffle=False,drop_last=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(test_dataset,batch_size=test_inputs.shape[0],pin_memory=True,shuffle=False,drop_last=True)\n",
    "# dataloader_val = torch.utils.data.DataLoader(val_dataset,batch_size=val_inputs.shape[0],shuffle=False,pin_memory=True,drop_last=True)\n",
    "# device = torch.device(\"cuda:{}\".formt(cfg.train['gpu']) if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd10df18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['inputs_test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce1a91",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "##### Load weights and params #####\n",
    "rerecord = False\n",
    "cfg.model.batch_converge=False\n",
    "epoch = 1000\n",
    "model = TiDHy.TiDHy(cfg.model, device, show_progress=cfg.train.show_progress).to(device)\n",
    "# set_seed(42)\n",
    "load_path = cfg.paths.ckpt_dir/'best.pth.tar'\n",
    "# load_path = sorted(list(cfg.paths.ckpt_dir.rglob('last_{}.pth.tar'.format(epoch))))[0]\n",
    "data_load = torch.load(load_path,map_location=device)\n",
    "model.load_state_dict(data_load['state_dict'])\n",
    "model.to(device)\n",
    "print('Loaded from {} epoch'.format(data_load['epoch']))\n",
    "epoch = data_load['epoch']-1\n",
    "\n",
    "\n",
    "# result_dict = load_results(model, dataloader_test, data_dict, device, cfg, epoch, rerecord=rerecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "fontsize=13\n",
    "\n",
    "clrs = np.array(['#1A237E','#7E57C2','#757575','#BDBDBD','#4CAF50','#FF9800','#795548','#FF4081','#00BCD4','#FF1744','#FFFFFF','#000000'])\n",
    "sys_clrs = ['#E3A19F','#E3BE53','#708090','#90CCA9','#B7522E','#B0E0E6','#A89AC2','#556B2F','#FF6F61','#87CEEB','#FFDAB9','#40E0D0']\n",
    "cmap_sys = ListedColormap(sys_clrs)\n",
    "clr_ind =[8,8,1,1,9,9]\n",
    "# clr2 = [sys_clrs[clr_ind[n]] for n in range(len(clr_ind))]\n",
    "clr_ind3 = [2,8,9]\n",
    "clr2b = [sys_clrs[clr_ind3[n]] for n in range(len(clr_ind3))]\n",
    "\n",
    "clrs_b = clrs[[0,1,2,9,4,6,7,8,11]]\n",
    "cmap = ListedColormap(clrs)\n",
    "# cmap_small = ListedColormap(clrs[:len(np.unique(full_state_z))])\n",
    "cmap_b = ListedColormap(clrs_b)\n",
    "cmap\n",
    "# cmap_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5434c",
   "metadata": {},
   "source": [
    "# Save Multi Seq Len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cae1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = [100,200,500,1000]\n",
    "\n",
    "cfg, result_dict = run_seq_len_model(seq_len, model, data_dict, device, 1500, cfg, rerun=False)\n",
    "\n",
    "data_dict, cfg = load_dataset(cfg)\n",
    "seq_len = sorted([int(el) for el in list(result_dict.keys())])\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2664017",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1fa3122",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "states_x_test = data_dict['states_x_test']\n",
    "states_z_test = data_dict['states_z_test']\n",
    "# states_z_test = data_dict['states_z']\n",
    "ssm_params = cfg.dataset.ssm_params\n",
    "##### Set up combinatorics of timescales #####\n",
    "lst = list(itertools.product([1, 0], repeat=3))\n",
    "lst2 = list(itertools.product(['F', 'S'], repeat=3))\n",
    "full_state_z = np.zeros(ssm_params['time_bins_test'],dtype=int)\n",
    "# full_state_z = np.zeros(ssm_params['time_bins_train'],dtype=int)\n",
    "for n in range(len(lst)):\n",
    "    full_state_z[np.apply_along_axis(lambda x: np.all(x == lst[n]),0,states_z_test)] = n\n",
    "\n",
    "\n",
    "save_figs = False\n",
    "p=-1\n",
    "W = result_dict['{}'.format(seq_len[p])]['W'].reshape(-1,result_dict['{}'.format(seq_len[p])]['W'].shape[-1])\n",
    "# b = result_dict['b'].reshape(-1,result_dict['b'].shape[-1])\n",
    "I = result_dict['{}'.format(seq_len[p])]['I'].reshape(-1,result_dict['{}'.format(seq_len[p])]['I'].shape[-1])\n",
    "Ihat = result_dict['{}'.format(seq_len[p])]['I_hat'].reshape(-1,result_dict['{}'.format(seq_len[p])]['I_hat'].shape[-1])\n",
    "Ibar = result_dict['{}'.format(seq_len[p])]['I_bar'].reshape(-1,result_dict['{}'.format(seq_len[p])]['I_bar'].shape[-1])\n",
    "R_hat = result_dict['{}'.format(seq_len[p])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[p])]['R_hat'].shape[-1])\n",
    "R_bar = result_dict['{}'.format(seq_len[p])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[p])]['R_bar'].shape[-1])\n",
    "R2_hat = result_dict['{}'.format(seq_len[p])]['R2_hat'].reshape(-1,result_dict['{}'.format(seq_len[p])]['R2_hat'].shape[-1])\n",
    "# Ut = result_dict['Ut'].reshape(-1,result_dict['Ut'].shape[-2],result_dict['Ut'].shape[-1])\n",
    "# ##### Plot dynamic matrices #####\n",
    "if cfg.model.low_rank_temp:\n",
    "    Uk = torch.bmm(model.temporal.unsqueeze(-1),model.temporal.unsqueeze(1)).data.cpu().detach()\n",
    "else:\n",
    "    Uk = model.temporal.data.cpu().detach().reshape(model.mix_dim,model.r_dim,model.r_dim)\n",
    "    U_t = torch.matmul(torch.Tensor(W[:,None,:]), model.temporal.unsqueeze(0).cpu().detach()).reshape(-1, model.r_dim, model.r_dim).numpy()\n",
    "As = np.stack([v for v in data_dict['As'].values()])\n",
    "bs = np.stack([v for v in data_dict['bs'].values()])\n",
    "nfig = 0\n",
    "fontsize=13\n",
    "# t = 0; dt = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "770f503d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from ssm.util import random_rotation, find_permutation\n",
    "inputs_train_SLDS=data_dict['inputs_train']\n",
    "inputs_test_SLDS=data_dict['inputs_test']\n",
    "seed = cfg.dataset.ssm_params['seed']\n",
    "# SLDS_path = Path('/data/users/eabe/hypernets/SLDS/TiDHy_SLDS/L1ShortWin/L1_alpha=0.001,dataset.ssm_params.seed=10,dataset.train.sequence_length=200')\n",
    "SLDS_path = cfg.paths.log_dir#/'SSM/DPC_SSM/Benchmark/dataset.ssm_params.seed={}/'.format(seed)\n",
    "N = inputs_train_SLDS.shape[-1]\n",
    "K = len(np.unique(full_state_z))\n",
    "D = data_dict['states_x_test'].shape[-1]\n",
    "with open(SLDS_path/'ssm_slds_test_full_{}D_{}K_{}seed.pickle'.format(D,K,seed), 'rb') as handle:\n",
    "# with open(cfg.paths.data_dir/'ssm_rslds_test.pickle', 'rb') as handle:\n",
    "    slds = pickle.load(handle)\n",
    "    posterior = pickle.load(handle)\n",
    "    SLDS_latents = pickle.load(handle)\n",
    "    SLDS_states = pickle.load(handle)\n",
    "    SLDS_emission = pickle.load(handle)\n",
    "\n",
    "with open(SLDS_path/'ssm_rslds_test_full_{}D_{}K_{}seed.pickle'.format(D,K,seed), 'rb') as handle:\n",
    "# with open(cfg.paths.data_dir/'ssm_rslds_test.pickle', 'rb') as handle:\n",
    "    slds = pickle.load(handle)\n",
    "    posterior = pickle.load(handle)\n",
    "    rSLDS_latents = pickle.load(handle)\n",
    "    rSLDS_states = pickle.load(handle)\n",
    "    rSLDS_emission = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537481f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from statsmodels.tsa.api import VAR\n",
    "\n",
    "nani = full_state_z.shape[0]\n",
    "ts=-1\n",
    "reg_variables = [\n",
    "    result_dict['{}'.format(seq_len[ts])]['R2_hat'],\n",
    "    result_dict['{}'.format(seq_len[ts])]['W'],\n",
    "    result_dict['{}'.format(seq_len[ts])]['R_bar'],\n",
    "    result_dict['{}'.format(seq_len[ts])]['R_hat'],\n",
    "    result_dict['{}'.format(seq_len[ts])]['I'],\n",
    "    SLDS_latents,]\n",
    "\n",
    "labels = ['R2_hat','W','R_bar','R_hat','I','SLDS']\n",
    "max_acc = 0\n",
    "tr_batch_size = 40\n",
    "batch_size = 10\n",
    "for k,reg_vars in enumerate(reg_variables):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reg_vars.reshape(-1,reg_vars.shape[-1]), full_state_z.reshape(-1), test_size=0.25, random_state=42)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    scores = neigh.score(X_test, y_test)\n",
    "    print(labels[k],scores)\n",
    "    if (scores > max_acc) & (labels[k] != 'I'):\n",
    "        y_pred = neigh.predict(reg_vars.reshape(-1,reg_vars.shape[-1]))\n",
    "        max_acc = scores\n",
    "        best_reg_vars = reg_vars\n",
    "        best_label = labels[k]\n",
    "        best_pred = y_pred\n",
    "\n",
    "state_compare = np.stack([rSLDS_states, SLDS_states,best_pred,full_state_z],axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "n_comps=ssm_params['latent_dim']\n",
    "t=1500; dt=200\n",
    "    \n",
    "fig = plt.figure(constrained_layout=True, figsize=(7,5.5))\n",
    "gs0 = gridspec.GridSpec(nrows=5,ncols=4, figure=fig, wspace=.45,hspace=.2)\n",
    "\n",
    "gs00 = gridspec.GridSpecFromSubplotSpec(nrows=6,ncols=1,subplot_spec=gs0[:,:2],wspace=.1,hspace=.2)\n",
    "# gs01 = gridspec.GridSpecFromSubplotSpec(3,1, subplot_spec=gs0[0:,:1],wspace=.05,hspace=.8)\n",
    "axs = np.array([fig.add_subplot(gs00[:-3,0]),\n",
    "                fig.add_subplot(gs00[-3:-2,0]),\n",
    "                fig.add_subplot(gs00[-2:,0]),\n",
    "                fig.add_subplot(gs0[:3,2:]),\n",
    "                fig.add_subplot(gs0[3:,2:])])\n",
    "axs[4].sharex(axs[3])\n",
    "ts = -1\n",
    "##### Pannel a #####\n",
    "I = result_dict['{}'.format(seq_len[ts])]['I'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I'].shape[-1])\n",
    "Ihat = result_dict['{}'.format(seq_len[ts])]['I_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I_hat'].shape[-1])\n",
    "# fig,axs = plt.subplots(1,2,figsize=(5,3),sharey=True,gridspec_kw={'wspace':.15,'width_ratios':[2,1]})\n",
    "ax = axs[0]\n",
    "spacing = 1\n",
    "xrange = 100\n",
    "cmap2,norm = map_discrete_cbar(cmap_b,len(np.unique(full_state_z)))\n",
    "linestyle =  (0, (5, 1))#(0, (5, 5))\n",
    "hlines_I,hlines_Ihat = [],[]\n",
    "for n in range(I.shape[-1]):\n",
    "    mean_centered_I = I[t:t+dt,n] - np.mean(I[t:t+dt,n],axis=0)\n",
    "    ax.plot(mean_centered_I + n/spacing,color='k', lw=2,zorder=1,label='Data')\n",
    "    hlines_I.append(np.mean(mean_centered_I + n/spacing,axis=0))\n",
    "    mean_centered_Ihat = Ihat[t:t+dt,n] - np.mean(Ihat[t:t+dt,n],axis=0)\n",
    "    ax.plot(mean_centered_Ihat + n/spacing, linestyle=linestyle, color='r', lw=1,zorder=2,label='Pred')\n",
    "    hlines_Ihat.append(np.mean(mean_centered_Ihat + n/spacing,axis=0))\n",
    "\n",
    "# ax.set_yticks(hlines_I)\n",
    "ax.set_yticks([])\n",
    "# ax.set_yticklabels(np.arange(1,len(hlines_I)+1),fontsize=fontsize-2)\n",
    "ax.set_ylabel('observations',fontsize=fontsize)\n",
    "ax.set_xticks(np.arange(0,dt+xrange,xrange))\n",
    "ax.set_xticklabels(np.arange(0,dt+xrange,xrange),fontsize=fontsize-2)\n",
    "ax.set_xlabel('timesteps',fontsize=fontsize)\n",
    "\n",
    "##### Pannel c #####\n",
    "ax = axs[3]\n",
    "count=0\n",
    "acc_slds = accuracy_score(full_state_z, SLDS_states)\n",
    "acc_rslds = accuracy_score(full_state_z, rSLDS_states)\n",
    "acc_TiDHy = accuracy_score(full_state_z, y_pred)\n",
    "spacing = .5\n",
    "\n",
    "hlines_x,hlines_Rhat = [],[]\n",
    "for p in range(ssm_params['Nlds']):\n",
    "    # states_x_cca = states_x_train[:,(ssm_params['latent_dim']*(p)):(p+1)*ssm_params['latent_dim']]\n",
    "    states_x_cca = states_x_test[:,(ssm_params['latent_dim']*(p)):(p+1)*ssm_params['latent_dim']]\n",
    "    # states_x_cca = states_x_test[:,p:p+1]\n",
    "    cca = CCA(n_components=ssm_params['latent_dim'],max_iter=1000)\n",
    "    X_c,Y_c = cca.fit_transform(states_x_cca,R_hat)\n",
    "    cca_coefficient = np.corrcoef(X_c.T, Y_c.T).diagonal(offset=n_comps)\n",
    "    x_w = cca.x_weights_\n",
    "    y_w = cca.y_weights_\n",
    "    cca_angles = [np.rad2deg(angle_between(X_c[:,n],Y_c[:,n])) for n in range(n_comps)]\n",
    "    cca_angles_x = [np.rad2deg(angle_between(X_c[:,n],states_x_cca[:,n])) for n in range(n_comps)]\n",
    "    cca_angles_r = [np.rad2deg(angle_between(Y_c[:,n],R_hat[:,n])) for n in range(n_comps)]\n",
    "    for n in range(n_comps):\n",
    "        print('comp {}, cc: {:.03}, ang: {:.03}, ang_x:{:.03}, ang_r:{:.03}'.format(n,cca_coefficient[n],cca_angles[n],cca_angles_x[n],cca_angles_r[n]))\n",
    "\n",
    "    for i in range(X_c.shape[-1]):\n",
    "        mean_centered_x = X_c[t:t+dt,i] - np.mean(X_c[t:t+dt,i],axis=0)\n",
    "        mean_centered_x=mean_centered_x/(np.max(np.abs(mean_centered_x)))\n",
    "        ax.plot(np.arange(0,dt),mean_centered_x + count/spacing,color='k', lw=2,zorder=1)\n",
    "        hlines_x.append(np.mean(mean_centered_x + count/spacing,axis=0))\n",
    "        mean_centered_Rhat = Y_c[t:t+dt,i] - np.mean(Y_c[t:t+dt,i],axis=0)\n",
    "        mean_centered_Rhat=mean_centered_Rhat/(np.max(np.abs(mean_centered_Rhat)))\n",
    "        ax.plot(np.arange(0,dt),mean_centered_Rhat + count/spacing,linestyle=linestyle,color='r', lw=1.5,zorder=2,label='$\\hat{{r}}_{{{}}}$={:.02}'.format(n,cca_coefficient[n]),alpha=1)\n",
    "        hlines_Rhat.append(np.mean(mean_centered_Rhat + count/spacing,axis=0))\n",
    "        ax.text(x=dt+15,y=hlines_x[count],s='cc = {:.02}'.format(cca_coefficient[i]),fontsize=fontsize-2)\n",
    "        count += 1\n",
    "    ax.set_yticks(hlines_x) \n",
    "    ax.set_yticklabels(np.arange(1,len(hlines_x)+1),fontsize=fontsize-2)\n",
    "    # ax.set_xlabel('Timesteps',fontsize=fontsize)\n",
    "    ax.set_ylabel('latent variables',fontsize=fontsize)\n",
    "# ax.set_xticks([])\n",
    "ax.set_xticks(np.arange(0,dt+200,200))\n",
    "ax.set_xticklabels(np.arange(0,dt+200,200),fontsize=fontsize-2)\n",
    "ax.set_xlabel('timesteps', fontsize=fontsize)\n",
    "# X,Y = np.meshgrid(np.arange(0,dt),np.arange(-1,2*6))\n",
    "# im = ax.pcolormesh(X,Y,np.tile(full_state_z[None,t:t+dt],(2*6+1,1)),cmap=cmap,norm=norm,alpha=.5,rasterized=True,zorder=-1)\n",
    "ax.legend(['data','pred'],frameon=False,fontsize=fontsize,loc='upper right',bbox_to_anchor=(1.1,1.1),labelcolor='linecolor',handlelength=0,handleheight=0,ncols=2,columnspacing=.1)\n",
    "\n",
    "##### Pannel b #####\n",
    "ax = axs[1]\n",
    "dts = 1/len(np.unique(full_state_z))\n",
    "y_ranges=np.repeat([[0,1]],3,axis=0)\n",
    "timescales_As = 1/np.abs(np.real(np.log(np.linalg.eigvals(As)))[:,:,0].reshape(-1))\n",
    "# timescales_As = 1/np.abs(np.log(np.real(np.linalg.eigvals(As)))[:,:,0].reshape(-1))\n",
    "evals_As = np.linalg.eigvals(As)[:,:,0].reshape(-1)\n",
    "R_bar = result_dict['{}'.format(seq_len[ts])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_bar'].shape[-1])\n",
    "R_hat = result_dict['{}'.format(seq_len[ts])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_hat'].shape[-1])\n",
    "Uhat_all = []\n",
    "for state in range(len(np.unique(full_state_z))):\n",
    "    rhat2 = R_hat[np.where(full_state_z==state)[0],:]\n",
    "    Uhat_0 = np.linalg.inv(rhat2[:-1].T@rhat2[:-1])@rhat2[:-1].T@rhat2[1:]\n",
    "    Uhat_all.append(Uhat_0)\n",
    "    \n",
    "# for p in range(ssm_params.Nlds):\n",
    "#     for state in range(ssm_params.n_disc_states):\n",
    "#         rhat2 = R_hat[np.where(states_z_test[p]==state)[0],:]\n",
    "#         Uhat_0 = np.linalg.inv(rhat2[:-1].T@rhat2[:-1])@rhat2[:-1].T@rhat2[1:]\n",
    "#         Uhat_all.append(Uhat_0)\n",
    "        \n",
    "Uhat_all = np.stack(Uhat_all)\n",
    "evals_Uhat_all = np.linalg.eigvals(Uhat_all).reshape(-1)\n",
    "timescales = 1/np.abs(np.real(np.log(evals_Uhat_all)))\n",
    "min_error_idx = np.array([np.argmin(np.abs(timescales.reshape(-1) - timescales_As.reshape(-1)[n])) for n in range(timescales_As.shape[0])])\n",
    "min_error_timescales = timescales[min_error_idx]\n",
    "# timescales = 1/np.abs(np.log(np.real(evals_Uhat_all)))\n",
    "ax.scatter(x=min_error_timescales,y=np.abs(evals_Uhat_all.reshape(-1)[min_error_idx]), marker='x',\n",
    "            c='k',s=50,alpha=1,edgecolor='None',zorder=3)\n",
    "for n in range(len(timescales_As)):\n",
    "    ax.axvline(x=timescales_As[n],c=sys_clrs[clr_ind[n]])\n",
    "    ax.scatter(x=timescales_As[n],y=np.abs(evals_As[n]),\n",
    "            c=sys_clrs[clr_ind[n]],s=40,alpha=1,edgecolor='None')\n",
    "ax.set_xscale('symlog',linthresh=.1)\n",
    "ax.set_yticks([0,.5,1])\n",
    "ax.set_ylim(0,1.1)\n",
    "ax.set_xlim(0.25,2.5e2)\n",
    "# ax.set_yticks([np.diff(y_ranges)[0,0]/2 + q*dts for q in range(len(np.unique(full_state_z)))])\n",
    "# ax.set_yticklabels([''.join(lst2[n]) for n in range(len(lst2))],fontsize=fontsize-2)\n",
    "# ax.set_xticks([0,-10e0,-10e-1])\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2)\n",
    "ax.set_ylabel('|$\\lambda$|',fontsize=fontsize)\n",
    "y = 1\n",
    "dy = 0.15\n",
    "ax.annotate('system 1', xy=(.01,y),xycoords='axes fraction',color=sys_clrs[clr_ind[0]],fontsize=fontsize-3.5)\n",
    "ax.annotate('system 2', xy=(.01,y-dy),xycoords='axes fraction',color=sys_clrs[clr_ind[2]],fontsize=fontsize-3.5)\n",
    "ax.annotate('system 3', xy=(.01,y-2*dy),xycoords='axes fraction',color=sys_clrs[clr_ind[4]],fontsize=fontsize-3.5)\n",
    "# ax.set_xticks([0,-10e0,-10e-1])\n",
    "ax.set_xlabel('timescales',fontsize=fontsize,labelpad=-1)\n",
    "\n",
    "######### Accuracy and reconstruction error #########\n",
    "ax = axs[2]\n",
    "Input_Errors_SLDS = np.abs(inputs_test_SLDS-SLDS_emission)\n",
    "Input_Errors_rSLDS = np.abs(inputs_test_SLDS-rSLDS_emission)\n",
    "Input_Errors = np.abs(I-result_dict['{}'.format(seq_len[ts])]['I_hat'])\n",
    "err_slds  = 100*(1-accuracy_score(full_state_z, SLDS_states))\n",
    "err_rslds = 100*(1-accuracy_score(full_state_z, rSLDS_states))\n",
    "err_TiDHy = 100*(1-accuracy_score(full_state_z, y_pred))\n",
    "ax.scatter(x=np.mean(Input_Errors_SLDS),y=err_slds, s=25, c=clrs[2],label='SLDS')\n",
    "ax.errorbar(x=np.mean(Input_Errors_SLDS),y=err_slds, ecolor=clrs[2],xerr=np.std(Input_Errors_SLDS))#/np.sqrt(len(Input_Errors_SLDS)))\n",
    "ax.scatter(x=np.mean(Input_Errors_rSLDS),y=err_rslds, s=25,c=clrs[6],label='rSLDS')\n",
    "ax.errorbar(x=np.mean(Input_Errors_rSLDS),y=err_rslds, ecolor=clrs[6],xerr=np.std(Input_Errors_rSLDS))#/np.sqrt(len(Input_Errors_SLDS)))\n",
    "ax.scatter(x=np.mean(Input_Errors),y=err_TiDHy, s=25, c=clrs[1],label='TiDHy')\n",
    "ax.errorbar(x=np.mean(Input_Errors),y=err_TiDHy, ecolor=clrs[1],xerr=np.std(Input_Errors))#/np.sqrt(len(Input_Errors_SLDS)))\n",
    "ax.set_yticks([0,25,50,75,100])\n",
    "ax.set_xlabel('reconstruction error',fontsize=fontsize)\n",
    "ax.set_ylabel('dyn. % error',fontsize=fontsize)\n",
    "ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0),useLocale=True)\n",
    "ax.legend(frameon=False,fontsize=fontsize-3,loc='upper right',bbox_to_anchor=(1.1,1.1),labelcolor='linecolor',handlelength=0,handleheight=0,ncols=1,columnspacing=.1)\n",
    "\n",
    "##### Pannel d #####\n",
    "ax = axs[4]\n",
    "ylabels_states = ['rSLDS \\n {:02}%'.format(int(np.round(acc_rslds*100))),\n",
    "                  'SLDS \\n {:02}%'.format(int(np.round(acc_slds*100))),\n",
    "                  'TiDHy \\n {:02}%'.format(int(np.round(acc_TiDHy*100))),\n",
    "                  'True']\n",
    "im = ax.pcolormesh(state_compare[:,t:t+dt],cmap=cmap2,norm=norm,alpha=.5,rasterized=True)\n",
    "ax.set_xticks(np.arange(0,dt+xrange,xrange))\n",
    "ax.set_xticklabels(np.arange(0,dt+xrange,xrange),fontsize=fontsize-2)\n",
    "ax.set_yticks(np.arange(.5,4,1))\n",
    "ax.set_yticklabels(ylabels_states,fontsize=fontsize-2)\n",
    "ax.set_xlabel('timesteps',fontsize=fontsize)\n",
    "\n",
    "cbar = fig.colorbar(im,ax=axs[-1],aspect=10, pad=-.2)\n",
    "\n",
    "cbar.set_ticks(np.arange(0,len(np.unique(full_state_z)),1))\n",
    "cbar.set_ticklabels([''.join(lst2[n]) for n in np.arange(len(lst2)-1,-1,-1)],fontsize=fontsize)\n",
    "cbar.outline.set_linewidth(1)\n",
    "cbar.minorticks_off()\n",
    "cbar.ax.tick_params(width=1,which=\"major\")\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(cfg.paths.fig_dir/'Benchmark_Compare3.pdf',dpi=300)\n",
    "fig.savefig(fig_path/'{}_Fig2_V2.pdf'.format(nfig),dpi=300, transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f56611",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nani = full_state_z.shape[0]\n",
    "ts=1\n",
    "best_pred_all = []\n",
    "acc_ssm = accuracy_score(full_state_z, SLDS_states)\n",
    "acc_TiDHy_all = []\n",
    "for ts in range(len(seq_len)):\n",
    "    reg_variables = [\n",
    "        # np.concatenate([result_dict['{}'.format(seq_len[ts])]['R2_hat'],result_dict['{}'.format(seq_len[ts])]['W']],axis=-1)\n",
    "        result_dict['{}'.format(seq_len[ts])]['R2_hat'],\n",
    "        # q_lem_x,\n",
    "        ]\n",
    "\n",
    "    labels = ['R2_hat']\n",
    "    # reg_variables = W\n",
    "    max_acc = 0\n",
    "    for k,reg_vars in enumerate(reg_variables):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reg_vars.reshape(-1,reg_vars.shape[-1]), full_state_z.reshape(-1), test_size=0.25, random_state=42)\n",
    "        neigh = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "        neigh.fit(X_train, y_train)\n",
    "        scores = neigh.score(X_test, y_test)\n",
    "        y_pred = neigh.predict(reg_vars.reshape(-1,reg_vars.shape[-1]))\n",
    "        print(labels[k],scores)\n",
    "        acc_TiDHy = accuracy_score(full_state_z, y_pred)\n",
    "        acc_TiDHy_all.append(acc_TiDHy)\n",
    "        best_pred_all.append(y_pred)\n",
    "\n",
    "state_compare = np.concatenate([SLDS_states[None,:],np.stack(best_pred_all),full_state_z[None,:]],axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbac2ec",
   "metadata": {},
   "source": [
    "## Load multi-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d49857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = [100,200,500,1000]\n",
    "\n",
    "result_dict_all = {}\n",
    "for n in range(len(configs)):\n",
    "    cfg_path =configs[n]# Path('/data/users/eabe/hypernets/SLDS/DPC_SLDS/TestingNoTempLearning/mix_dim=15/config.yaml')\n",
    "    default_model_config = '/home/eabe/Research/MyRepos/HyperNets/conf/dataset/model/default_model.yaml'\n",
    "    cfg = load_cfg(cfg_path, default_model_config)\n",
    "    cfg, result_dict = run_seq_len_model(seq_len, model, data_dict, device, 1500, cfg, rerun=False)\n",
    "    result_dict_all['seed_{}'.format(cfg.dataset.ssm_params.seed)] = result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values\n",
    "seeds = np.arange(10,10+len(configs))\n",
    "seed = 10\n",
    "ts = 200\n",
    "\n",
    "##### Set up combinatorics of timescales #####\n",
    "ssm_params = cfg.dataset.ssm_params\n",
    "lst = list(itertools.product([0, 1], repeat=3))\n",
    "lst2 = list(itertools.product(['F', 'S'], repeat=3))\n",
    "full_state_z = np.zeros((len(seeds),ssm_params['time_bins_test']),dtype=int)\n",
    "# full_state_z = np.zeros(ssm_params['time_bins_train'],dtype=int)\n",
    "for i, seed in enumerate(seeds):\n",
    "    for n in range(len(lst)):\n",
    "        full_state_z[i,np.apply_along_axis(lambda x: np.all(x == lst[n]),0,result_dict_all[f'seed_{seed}'][f'{ts}']['states_z_test'])] = n\n",
    "    \n",
    "I_all = np.stack([result_dict_all[f'seed_{seed}'][f'{ts}']['I'] for seed in seeds])\n",
    "I_hat_all = np.stack([result_dict_all[f'seed_{seed}'][f'{ts}']['I_hat'] for seed in seeds])\n",
    "R2_hat_all = np.stack([np.stack([result_dict_all[f'seed_{seed}'][f'{ts}']['R2_hat'] for ts in seq_len])for seed in seeds])  # (n_seeds, Time, Z_dim)\n",
    "R_bar_all = np.stack([np.stack([result_dict_all[f'seed_{seed}'][f'{ts}']['R_bar'] for ts in seq_len]) for seed in seeds])   # (n_seeds, TempWinN, Time, r2_dim)\n",
    "R_hat_all = np.stack([np.stack([result_dict_all[f'seed_{seed}'][f'{ts}']['R_hat'] for ts in seq_len]) for seed in seeds])   # (n_seeds, TempWinN, Time, r_dim)\n",
    "W_all = np.stack([np.stack([result_dict_all[f'seed_{seed}'][f'{ts}']['W'] for ts in seq_len]) for seed in seeds])           # (n_seeds, TempWinN, Time, r_dim)\n",
    "As_all = np.stack([np.stack([v for v in result_dict_all[f'seed_{seed}'][f'{ts}']['As'].values()]) for seed in seeds])\n",
    "result_dict_all[f'seed_{seed}'][f'{ts}'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fac0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from ssm.util import random_rotation, find_permutation\n",
    "inputs_train_SLDS=data_dict['inputs_train']\n",
    "inputs_test_SLDS=data_dict['inputs_test']\n",
    "seed = cfg.dataset.ssm_params['seed']\n",
    "TotalTime = cfg.dataset.ssm_params.time_bins_test\n",
    "# SLDS_path = Path('/data/users/eabe/hypernets/SLDS/TiDHy_SLDS/L1ShortWin/L1_alpha=0.001,dataset.ssm_params.seed=10,dataset.train.sequence_length=200')\n",
    "N = inputs_train_SLDS.shape[-1]\n",
    "K = len(np.unique(full_state_z))\n",
    "D = data_dict['states_x_test'].shape[-1]\n",
    "SLDS_latents = np.zeros((len(seeds),TotalTime,D))\n",
    "SLDS_states = np.zeros((len(seeds),TotalTime))\n",
    "SLDS_emission = np.zeros((len(seeds),TotalTime,N))\n",
    "rSLDS_latents = np.zeros((len(seeds),TotalTime,D))\n",
    "rSLDS_states = np.zeros((len(seeds),TotalTime))\n",
    "rSLDS_emission = np.zeros((len(seeds),TotalTime,N))\n",
    "for k, seed in enumerate(seeds):\n",
    "    SLDS_path = configs[k].parent#/'SSM/DPC_SSM/Benchmark/dataset.ssm_params.seed={}/'.format(seed)\n",
    "    with open(SLDS_path/'ssm_slds_test_full_{}D_{}K_{}seed.pickle'.format(D,K,seed), 'rb') as handle:\n",
    "    # with open(cfg.paths.data_dir/'ssm_rslds_test.pickle', 'rb') as handle:\n",
    "        slds = pickle.load(handle)\n",
    "        posterior = pickle.load(handle)\n",
    "        SLDS_latents[k] = pickle.load(handle)\n",
    "        SLDS_states[k] = pickle.load(handle)\n",
    "        SLDS_emission[k] = pickle.load(handle)\n",
    "\n",
    "    with open(SLDS_path/'ssm_rslds_test_full_{}D_{}K_{}seed.pickle'.format(D,K,seed), 'rb') as handle:\n",
    "    # with open(cfg.paths.data_dir/'ssm_rslds_test.pickle', 'rb') as handle:\n",
    "        slds = pickle.load(handle)\n",
    "        posterior = pickle.load(handle)\n",
    "        rSLDS_latents[k] = pickle.load(handle)\n",
    "        rSLDS_states[k] = pickle.load(handle)\n",
    "        rSLDS_emission[k] = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from statsmodels.tsa.api import VAR\n",
    "\n",
    "nani = full_state_z.shape[0]\n",
    "ts=-1\n",
    "\n",
    "labels = seeds\n",
    "max_acc = 0\n",
    "tr_batch_size = 40\n",
    "batch_size = 10\n",
    "scores_all = []\n",
    "pred_all = np.zeros((len(seeds),len(seq_len),cfg.dataset.ssm_params.time_bins_test))\n",
    "for k in range(len(seeds)):\n",
    "    for ts in range(len(seq_len)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(R2_hat_all[k,ts], full_state_z[k].reshape(-1), test_size=0.25, random_state=42)\n",
    "        neigh = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "        neigh.fit(X_train, y_train)\n",
    "        scores = neigh.score(X_test, y_test)\n",
    "        y_pred = neigh.predict(R2_hat_all[k,ts])\n",
    "        pred_all[k,ts] = y_pred\n",
    "        scores_all.append(accuracy_score(full_state_z[k].reshape(-1),y_pred))\n",
    "        print(labels[k],seq_len[ts],scores)\n",
    "        if (scores > max_acc) & (labels[k] != 'I'):\n",
    "            max_acc = scores\n",
    "            best_label = k\n",
    "            best_pred = y_pred\n",
    "\n",
    "# state_compare = np.stack([rSLDS_states, SLDS_states,best_pred,full_state_z[best_label]],axis=0)\n",
    "\n",
    "scores_all = np.stack(scores_all).reshape(len(seeds),len(seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f817574",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(8,6))\n",
    "gs0 = gridspec.GridSpec(nrows=4,ncols=2, figure=fig, wspace=.15,hspace=.2)\n",
    "axs = np.array([fig.add_subplot(gs0[:2,0]),fig.add_subplot(gs0[2:,0]),fig.add_subplot(gs0[:2,1]),fig.add_subplot(gs0[2:,1])])\n",
    "t=1500; dt=1000\n",
    "# seq_len=[100,200,500]\n",
    "ts = 1\n",
    "Input_Errors_SLDS = (I_all[k]-SLDS_emission[k])\n",
    "ax = axs[-1]\n",
    "Input_Errors_SLDS = np.mean([np.abs(I_all[k]-SLDS_emission[k]) for k in range(len(seeds))],axis=-1)\n",
    "Input_Errors_rSLDS = np.mean([np.abs(I_all[k]-rSLDS_emission[k]) for k in range(len(seeds))],axis=-1)\n",
    "err_slds  = np.mean([100*(1-accuracy_score(full_state_z[k], SLDS_states[k])) for k in range(len(seeds))])\n",
    "err_rslds = np.mean([100*(1-accuracy_score(full_state_z[k], rSLDS_states[k])) for k in range(len(seeds))])\n",
    "for ts in range(len(seq_len)):\n",
    "    Input_Errors =np.stack([np.abs(I_all[seed,ts]-I_hat_all[seed,ts]) for seed in range(len(seeds))])\n",
    "    err_TiDHy = np.mean([100*(1-accuracy_score(full_state_z[k], pred_all[k,ts])) for k in range(len(seeds))])\n",
    "    ax.scatter(x=np.mean(Input_Errors),y=err_TiDHy, s=25, c=clrs_b[ts],label='TiDHy')\n",
    "    ax.errorbar(x=np.mean(Input_Errors),y=err_TiDHy, ecolor=clrs_b[ts],xerr=np.mean(np.std(Input_Errors,axis=-1)),yerr=np.mean(np.std(Input_Errors,axis=0)))#/np.sqrt(len(Input_Errors_SLDS)))\n",
    "\n",
    "ax.scatter(x=np.mean(Input_Errors_SLDS),y=err_slds, s=25, c=clrs[2],label='SLDS')\n",
    "ax.errorbar(x=np.mean(Input_Errors_SLDS),y=err_slds, ecolor=clrs[2],xerr=np.std(Input_Errors_SLDS))#/np.sqrt(len(Input_Errors_SLDS)))\n",
    "ax.scatter(x=np.mean(Input_Errors_rSLDS),y=np.mean(err_rslds), s=25,c=clrs[6],label='rSLDS')\n",
    "ax.errorbar(x=np.mean(Input_Errors_rSLDS),y=np.mean(err_rslds), ecolor=clrs[6],xerr=np.std(Input_Errors_rSLDS))#/np.sqrt(len(Input_Errors_SLDS)))\n",
    "ax.set_yticks([0,25,50,75,100])\n",
    "ax.set_xlabel('reconstruction error',fontsize=fontsize)\n",
    "ax.set_ylabel('dyn. % error',fontsize=fontsize)\n",
    "ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0),useLocale=True)\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2)\n",
    "ax.tick_params(axis='y', labelsize=fontsize-2)\n",
    "y = .95\n",
    "dy = 0.075\n",
    "for tts in range(len(seq_len)):\n",
    "    ax.annotate('T={}'.format(seq_len[tts]), xy=(.8,y-tts*dy),xycoords='axes fraction',color=clrs_b[tts],fontsize=fontsize-2)\n",
    "tts+=1\n",
    "ax.annotate('SLDS', xy=(.8,y-tts*dy),xycoords='axes fraction',color=clrs[2],fontsize=fontsize-2)\n",
    "tts += 1\n",
    "ax.annotate('rSLDS', xy=(.8,y-tts*dy),xycoords='axes fraction',color=clrs[6],fontsize=fontsize-2)\n",
    "\n",
    "\n",
    "states_z_test = data_dict['states_z_test']\n",
    "ax = axs[2]\n",
    "As = np.stack([v for v in data_dict['As'].values()])\n",
    "timescales_As = 1/np.abs(np.real(np.log(np.linalg.eigvals(As)))[:,:,0].reshape(-1))\n",
    "# timescales_As = 1/np.abs(np.log(np.real(np.linalg.eigvals(As)))[:,:,0].reshape(-1))\n",
    "ts = 0\n",
    "dts = 1/len(seq_len)\n",
    "y_ranges = np.arange(0,1,(dts*dts)).reshape(-1,len(seq_len))[:,(0,-1)]\n",
    "for ts in range(len(seq_len)):\n",
    "    for seed in seeds: \n",
    "        R_bar = result_dict_all['seed_{}'.format(seed)]['{}'.format(seq_len[ts])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_bar'].shape[-1])\n",
    "        R_hat = result_dict_all['seed_{}'.format(seed)]['{}'.format(seq_len[ts])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_hat'].shape[-1])\n",
    "\n",
    "        ##### Plottign Eigenvalues #####\n",
    "        Uhat_all = []\n",
    "        for state in range(len(np.unique(full_state_z[0]))):\n",
    "            # rhat2 = R_hat[np.where(full_state_z==state)[0],:]\n",
    "            # model = VAR(rhat2)\n",
    "            # results = model.fit(maxlags=20,ic='aic')\n",
    "            # eig_Ut = np.linalg.eigvals(results.coefs).reshape(-1)\n",
    "            # Uhat_all.append(eig_Ut.reshape(-1))\n",
    "        # for p in range(ssm_params.Nlds):\n",
    "        #     for state in range(ssm_params.n_disc_states):\n",
    "                # rhat2 = R_hat[np.where(states_z_test[p]==state)[0],:]\n",
    "            rhat2 = R_hat[np.where(full_state_z[0]==state)[0],:]\n",
    "            Uhat_0 = np.linalg.inv(rhat2[:-1].T@rhat2[:-1])@rhat2[:-1].T@rhat2[1:]\n",
    "            Uhat_all.append(Uhat_0)\n",
    "\n",
    "        Uhat_all = np.stack(Uhat_all)\n",
    "        # evals_Uhat_all = np.hstack(Uhat_all)\n",
    "        # timescales = 1/np.abs(np.log(np.real(evals_Uhat_all)))\n",
    "        # timescales = np.real(np.log(Uhat_all))\n",
    "        evals_Uhat_all = np.linalg.eigvals(Uhat_all).reshape(-1)\n",
    "        timescales = 1/np.abs(np.real(np.log(evals_Uhat_all)))\n",
    "        # timescales = 1/np.abs(np.log(np.real(evals_Uhat_all)))\n",
    "        min_error_idx = np.array([np.argmin(np.abs(timescales.reshape(-1) - timescales_As.reshape(-1)[n])) for n in range(timescales_As.shape[0])])\n",
    "        min_error_timescales = timescales[min_error_idx]\n",
    "        ax.scatter(x=min_error_timescales,y=np.abs(evals_Uhat_all.reshape(-1)[min_error_idx])+ts,\n",
    "                c=clrs_b[ts],alpha=.75,edgecolor='None',marker='x',s=25,zorder=3)\n",
    "\n",
    "    for n in range(len(timescales_As)):\n",
    "        ax.axvline(x=timescales_As[n],c=sys_clrs[clr_ind[n]])\n",
    "        ax.axhline(y=ts,c=clrs_b[ts],linestyle='--',zorder=-1)\n",
    "    # ax = plot_hist(timescales,-1.75,.1,.1,ax,'TiDHy',clr=clrs_b[ts])\n",
    "    ax.set_xscale('symlog',linthresh=.1)\n",
    "    ax.set_yticks([1/2 + q for q in range(len(seq_len))])\n",
    "    ax.set_yticklabels(seq_len,fontsize=fontsize-2)\n",
    "    ax.set_ylabel('T',fontsize=fontsize,labelpad=-2)\n",
    "    # ax.spines.left.set_visible(False)\n",
    "    ax.set_xlabel('timescales',fontsize=fontsize,labelpad=-3)\n",
    "# ax.set_xticks([0,-10e0,-10e-1])\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2)\n",
    "ax.set_xscale('symlog',linthresh=.015)\n",
    "y = .99\n",
    "dy = 0.075\n",
    "ax.annotate('System 1', xy=(.01,y),xycoords='axes fraction',color=sys_clrs[clr_ind[0]],fontsize=fontsize-2)\n",
    "ax.annotate('System 2', xy=(.01,y-dy),xycoords='axes fraction',color=sys_clrs[clr_ind[2]],fontsize=fontsize-2)\n",
    "ax.annotate('System 3', xy=(.01,y-2*dy),xycoords='axes fraction',color=sys_clrs[clr_ind[4]],fontsize=fontsize-2)\n",
    "\n",
    "ax=axs[0]\n",
    "spacing= 5\n",
    "for p in range(len(seq_len)):\n",
    "    hlines_x = []\n",
    "    for n in range(result_dict['{}'.format(seq_len[p])]['R_hat'].shape[-1]):\n",
    "        trace = result_dict['{}'.format(seq_len[p])]['R_hat'][t:t+dt,n]\n",
    "        mean_centered_x = trace - np.mean(trace,axis=0)\n",
    "        ax.plot(mean_centered_x + n/spacing, lw=1,zorder=1,c=clrs_b[p],alpha=.5)\n",
    "        hlines_x.append(np.mean(mean_centered_x + n/spacing,axis=0))\n",
    "ax.set_ylabel('$\\hat{r}$',fontsize=fontsize,labelpad=-2)\n",
    "ax.set_xlabel('timesteps',fontsize=fontsize)\n",
    "ax.set_xticks(np.arange(0,dt+(dt//4),(dt)//4))\n",
    "ax.set_xticklabels(np.arange(0,dt+(dt//4),(dt)//4),fontsize=fontsize-2)\n",
    "ax.set_yticks(hlines_x)\n",
    "ax.set_yticklabels(np.arange(1,len(hlines_x)+1),fontsize=fontsize-2)\n",
    "ax.set_xlim([0,dt])\n",
    "y = .95\n",
    "dy = 0.075\n",
    "for tts in range(len(seq_len)):\n",
    "    ax.annotate('T={}'.format(seq_len[tts]), xy=(1.05,y-tts*dy),xycoords='axes fraction',color=clrs_b[tts],fontsize=fontsize-2)\n",
    "\n",
    "# legend = ax.legend(['T={}'.format(seq_len[p]) for p in range(len(seq_len))],frameon=False,fontsize=fontsize,loc='upper right',\n",
    "#           bbox_to_anchor=(1.25,1),labelcolor=clrs_b,handlelength=0,handleheight=0,ncols=1)\n",
    "\n",
    "\n",
    "ax = axs[1]\n",
    "state_compare = np.concatenate([SLDS_states[:1,:],pred_all[0],full_state_z[:1,:]],axis=0)\n",
    "cmap2,norm = map_discrete_cbar(cmap_b,len(np.unique(full_state_z[0])))\n",
    "acc_slds = accuracy_score(full_state_z[0], SLDS_states[0])\n",
    "TiDHy_acc = ['T={} \\n {:02}%'.format(seq_len[n],int(np.round(scores_all[0,n]*100))) for n in range(len(scores_all[0]))]\n",
    "Ylabels = ['SLDS \\n {:02}%'.format(int(np.round(acc_slds*100)))] + TiDHy_acc + ['True']  \n",
    "im = ax.pcolormesh(state_compare[:,t:t+dt],cmap=cmap2,norm=norm,alpha=.5,rasterized=True)\n",
    "# ax.set_xticks(np.arange(0,dt+200,200))\n",
    "# ax.set_xticklabels(np.arange(0,dt+200,200),fontsize=fontsize)\n",
    "ax.set_xticks(np.arange(0,dt+(dt//4),(dt)//4))\n",
    "ax.set_xticklabels(np.arange(0,dt+(dt//4),(dt)//4),fontsize=fontsize-2)\n",
    "ax.set_yticks(np.arange(.5,len(Ylabels),1))\n",
    "ax.set_yticklabels(Ylabels,fontsize=fontsize-2)\n",
    "ax.set_xlabel('timesteps',fontsize=fontsize)\n",
    "\n",
    "cbar = fig.colorbar(im,ax=ax,aspect=10, pad=-.2)\n",
    "cbar.set_ticks(np.arange(0,len(np.unique(full_state_z)),1))\n",
    "cbar.set_ticklabels([''.join(lst2[n]) for n in np.arange(len(lst2)-1,-1,-1)],fontsize=fontsize)\n",
    "cbar.outline.set_linewidth(1)\n",
    "cbar.minorticks_off()\n",
    "cbar.ax.tick_params(width=1,which=\"major\")\n",
    "fig.savefig(fig_path/'{}_Fig3.pdf'.format(0),dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 1\n",
    "Input_Errors = np.abs(I-result_dict['{}'.format(seq_len[ts])]['I_hat'])\n",
    "np.mean(Input_Errors),np.std(Input_Errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38dd9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(8,6))\n",
    "gs0 = gridspec.GridSpec(nrows=4,ncols=2, figure=fig, wspace=.15,hspace=.2)\n",
    "axs = np.array([fig.add_subplot(gs0[:2,0]),fig.add_subplot(gs0[2:,0]),fig.add_subplot(gs0[:2,1]),fig.add_subplot(gs0[2:,1])])\n",
    "t=1500; dt=1000\n",
    "# seq_len=[100,200,500]\n",
    "\n",
    "Input_Errors_SLDS = (inputs_test_SLDS-SLDS_emission)\n",
    "ax = axs[0]\n",
    "Input_Errors_SLDS = np.abs(inputs_test_SLDS-SLDS_emission)\n",
    "Input_Errors_rSLDS = np.abs(inputs_test_SLDS-rSLDS_emission)\n",
    "err_slds  = 100*(1-accuracy_score(full_state_z, SLDS_states))\n",
    "err_rslds = 100*(1-accuracy_score(full_state_z, rSLDS_states))\n",
    "for ts in range(len(seq_len)):\n",
    "    Input_Errors = np.abs(I-result_dict['{}'.format(seq_len[ts])]['I_hat'])\n",
    "    err_TiDHy = 100*(1-accuracy_score(full_state_z, y_pred))\n",
    "    ax.scatter(x=np.mean(Input_Errors),y=err_TiDHy, s=25, c=clrs_b[ts],label='TiDHy')\n",
    "    ax.errorbar(x=np.mean(Input_Errors),y=err_TiDHy, ecolor=clrs_b[ts],xerr=np.std(Input_Errors))#/np.sqrt(len(Input_Errors_SLDS)))\n",
    "\n",
    "ax.scatter(x=np.mean(Input_Errors_SLDS),y=err_slds, s=25, c=clrs[2],label='SLDS')\n",
    "ax.errorbar(x=np.mean(Input_Errors_SLDS),y=err_slds, ecolor=clrs[2],xerr=np.std(Input_Errors_SLDS))#/np.sqrt(len(Input_Errors_SLDS)))\n",
    "ax.scatter(x=np.mean(Input_Errors_rSLDS),y=err_rslds, s=25,c=clrs[6],label='rSLDS')\n",
    "ax.errorbar(x=np.mean(Input_Errors_rSLDS),y=err_rslds, ecolor=clrs[6],xerr=np.std(Input_Errors_rSLDS))#/np.sqrt(len(Input_Errors_SLDS)))\n",
    "ax.set_yticks([0,25,50,75,100])\n",
    "ax.set_xlabel('reconstruction error',fontsize=fontsize)\n",
    "ax.set_ylabel('dyn. % error',fontsize=fontsize)\n",
    "ax.ticklabel_format(axis='x', style='sci', scilimits=(0,0),useLocale=True)\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2)\n",
    "ax.tick_params(axis='y', labelsize=fontsize-2)\n",
    "y = .95\n",
    "dy = 0.075\n",
    "for tts in range(len(seq_len)):\n",
    "    ax.annotate('T={}'.format(seq_len[tts]), xy=(.8,y-tts*dy),xycoords='axes fraction',color=clrs_b[tts],fontsize=fontsize-2)\n",
    "tts+=1\n",
    "ax.annotate('SLDS', xy=(.8,y-tts*dy),xycoords='axes fraction',color=clrs[2],fontsize=fontsize-2)\n",
    "tts += 1\n",
    "ax.annotate('rSLDS', xy=(.8,y-tts*dy),xycoords='axes fraction',color=clrs[6],fontsize=fontsize-2)\n",
    "\n",
    "\n",
    "states_z_test = data_dict['states_z_test']\n",
    "ax = axs[1]\n",
    "As = np.stack([v for v in data_dict['As'].values()])\n",
    "timescales_As = 1/np.abs(np.real(np.log(np.linalg.eigvals(As)))[:,:,0].reshape(-1))\n",
    "ts = 0\n",
    "dts = 1/len(seq_len)\n",
    "y_ranges = np.arange(0,1,(dts*dts)).reshape(-1,len(seq_len))[:,(0,-1)]\n",
    "for ts in range(len(seq_len)):\n",
    "    R_bar = result_dict['{}'.format(seq_len[ts])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_bar'].shape[-1])\n",
    "    R_hat = result_dict['{}'.format(seq_len[ts])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_hat'].shape[-1])\n",
    "\n",
    "    ##### Plottign Eigenvalues #####\n",
    "    Uhat_all = []\n",
    "    for state in range(len(np.unique(full_state_z))):\n",
    "        # rhat2 = R_hat[np.where(full_state_z==state)[0],:]\n",
    "        # model = VAR(rhat2)\n",
    "        # results = model.fit(maxlags=20,ic='aic')\n",
    "        # eig_Ut = np.linalg.eigvals(results.coefs).reshape(-1)\n",
    "        # Uhat_all.append(eig_Ut.reshape(-1))\n",
    "    # for p in range(ssm_params.Nlds):\n",
    "    #     for state in range(ssm_params.n_disc_states):\n",
    "            # rhat2 = R_hat[np.where(states_z_test[p]==state)[0],:]\n",
    "        rhat2 = R_hat[np.where(full_state_z==state)[0],:]\n",
    "        Uhat_0 = np.linalg.inv(rhat2[:-1].T@rhat2[:-1])@rhat2[:-1].T@rhat2[1:]\n",
    "        Uhat_all.append(Uhat_0)\n",
    "\n",
    "    Uhat_all = np.stack(Uhat_all)\n",
    "    # evals_Uhat_all = np.hstack(Uhat_all)\n",
    "    # timescales = 1/np.abs(np.log(np.real(evals_Uhat_all)))\n",
    "    # timescales = np.real(np.log(Uhat_all))\n",
    "    evals_Uhat_all = np.linalg.eigvals(Uhat_all).reshape(-1)\n",
    "    timescales = 1/np.abs(np.real(np.log(evals_Uhat_all)))\n",
    "    \n",
    "    ax.scatter(x=timescales,y=np.abs(evals_Uhat_all)+ts,\n",
    "               c=clrs_b[ts],alpha=.75,edgecolor='None',s=25)\n",
    "\n",
    "    for n in range(len(timescales_As)):\n",
    "        ax.axvline(x=timescales_As[n],c=sys_clrs[clr_ind[n]])\n",
    "        ax.axhline(y=ts,c=clrs_b[ts],linestyle='--',zorder=-1)\n",
    "    # ax = plot_hist(timescales,-1.75,.1,.1,ax,'TiDHy',clr=clrs_b[ts])\n",
    "    ax.set_xscale('symlog',linthresh=.1)\n",
    "    ax.set_yticks([1/2 + q for q in range(len(seq_len))])\n",
    "    ax.set_yticklabels(seq_len,fontsize=fontsize-2)\n",
    "    ax.set_ylabel('T',fontsize=fontsize,labelpad=-2)\n",
    "    # ax.spines.left.set_visible(False)\n",
    "    ax.set_xlabel('timescales',fontsize=fontsize,labelpad=-3)\n",
    "# ax.set_xticks([0,-10e0,-10e-1])\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2)\n",
    "ax.set_xscale('symlog',linthresh=.015)\n",
    "y = .99\n",
    "dy = 0.075\n",
    "ax.annotate('System 1', xy=(.01,y),xycoords='axes fraction',color=sys_clrs[clr_ind[0]],fontsize=fontsize-2)\n",
    "ax.annotate('System 2', xy=(.01,y-dy),xycoords='axes fraction',color=sys_clrs[clr_ind[2]],fontsize=fontsize-2)\n",
    "ax.annotate('System 3', xy=(.01,y-2*dy),xycoords='axes fraction',color=sys_clrs[clr_ind[4]],fontsize=fontsize-2)\n",
    "\n",
    "ax=axs[2]\n",
    "spacing= 5\n",
    "for p in range(len(seq_len)):\n",
    "    hlines_x = []\n",
    "    for n in range(result_dict['{}'.format(seq_len[p])]['R_hat'].shape[-1]):\n",
    "        trace = result_dict['{}'.format(seq_len[p])]['R_hat'][t:t+dt,n]\n",
    "        mean_centered_x = trace - np.mean(trace,axis=0)\n",
    "        ax.plot(mean_centered_x + n/spacing, lw=1,zorder=1,c=clrs_b[p],alpha=.5)\n",
    "        hlines_x.append(np.mean(mean_centered_x + n/spacing,axis=0))\n",
    "ax.set_ylabel('$\\hat{r}$',fontsize=fontsize,labelpad=-2)\n",
    "ax.set_xlabel('timesteps',fontsize=fontsize)\n",
    "ax.set_xticks(np.arange(0,dt+(dt//4),(dt)//4))\n",
    "ax.set_xticklabels(np.arange(0,dt+(dt//4),(dt)//4),fontsize=fontsize-2)\n",
    "ax.set_yticks(hlines_x)\n",
    "ax.set_yticklabels(np.arange(1,len(hlines_x)+1),fontsize=fontsize-2)\n",
    "ax.set_xlim([0,dt])\n",
    "y = .95\n",
    "dy = 0.075\n",
    "for tts in range(len(seq_len)):\n",
    "    ax.annotate('T={}'.format(seq_len[tts]), xy=(1.05,y-tts*dy),xycoords='axes fraction',color=clrs_b[tts],fontsize=fontsize-2)\n",
    "\n",
    "# legend = ax.legend(['T={}'.format(seq_len[p]) for p in range(len(seq_len))],frameon=False,fontsize=fontsize,loc='upper right',\n",
    "#           bbox_to_anchor=(1.25,1),labelcolor=clrs_b,handlelength=0,handleheight=0,ncols=1)\n",
    "\n",
    "\n",
    "ax = axs[3]\n",
    "TiDHy_acc = ['T={} \\n {:02}%'.format(seq_len[n],int(np.round(acc_TiDHy_all[n]*100))) for n in range(len(acc_TiDHy_all))]\n",
    "Ylabels = ['SLDS \\n {:02}%'.format(int(np.round(acc_ssm*100)))] + TiDHy_acc + ['True']  \n",
    "im = ax.pcolormesh(state_compare[:,t:t+dt],cmap=cmap2,norm=norm,alpha=.5,rasterized=True)\n",
    "# ax.set_xticks(np.arange(0,dt+200,200))\n",
    "# ax.set_xticklabels(np.arange(0,dt+200,200),fontsize=fontsize)\n",
    "ax.set_xticks(np.arange(0,dt+(dt//4),(dt)//4))\n",
    "ax.set_xticklabels(np.arange(0,dt+(dt//4),(dt)//4),fontsize=fontsize-2)\n",
    "ax.set_yticks(np.arange(.5,len(Ylabels),1))\n",
    "ax.set_yticklabels(Ylabels,fontsize=fontsize-2)\n",
    "ax.set_xlabel('timesteps',fontsize=fontsize)\n",
    "\n",
    "cbar = fig.colorbar(im,ax=ax,aspect=10, pad=-.2)\n",
    "cbar.set_ticks(np.arange(0,len(np.unique(full_state_z)),1))\n",
    "cbar.set_ticklabels([''.join(lst2[n]) for n in np.arange(len(lst2)-1,-1,-1)],fontsize=fontsize)\n",
    "cbar.outline.set_linewidth(1)\n",
    "cbar.minorticks_off()\n",
    "cbar.ax.tick_params(width=1,which=\"major\")\n",
    "fig.savefig(cfg.paths.fig_dir/'{}_Fig3.pdf'.format(nfig),dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60973a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trade off plot between accuracy of reconstruction and correct identification of unique timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1,figsize=(5,3))\n",
    "ax = axs\n",
    "dts = 1/len(np.unique(full_state_z))\n",
    "y_ranges=np.repeat([[0,1]],3,axis=0)\n",
    "timescales_As = 1/np.abs(np.real(np.log(np.linalg.eigvals(As)))[:,:,0].reshape(-1))\n",
    "evals_As = np.linalg.eigvals(As)[:,:,0].reshape(-1)\n",
    "R_bar = result_dict['{}'.format(seq_len[ts])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_bar'].shape[-1])\n",
    "R_hat = result_dict['{}'.format(seq_len[ts])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_hat'].shape[-1])\n",
    "Uhat_all = []\n",
    "for state in range(len(np.unique(full_state_z))):\n",
    "    rhat2 = R_hat[np.where(full_state_z==state)[0],:]\n",
    "    Uhat_0 = np.linalg.inv(rhat2[:-1].T@rhat2[:-1])@rhat2[:-1].T@rhat2[1:]\n",
    "    Uhat_all.append(Uhat_0)\n",
    "    \n",
    "# for p in range(ssm_params.Nlds):\n",
    "#     for state in range(ssm_params.n_disc_states):\n",
    "#         rhat2 = R_hat[np.where(states_z_test[p]==state)[0],:]\n",
    "#         Uhat_0 = np.linalg.inv(rhat2[:-1].T@rhat2[:-1])@rhat2[:-1].T@rhat2[1:]\n",
    "#         Uhat_all.append(Uhat_0)\n",
    "        \n",
    "Uhat_all = np.stack(Uhat_all)\n",
    "evals_Uhat_all = np.linalg.eigvals(Uhat_all).reshape(-1)\n",
    "timescales = 1/np.abs(np.real(np.log(evals_Uhat_all)))\n",
    "ax.scatter(x=timescales,y=np.abs(evals_Uhat_all),\n",
    "            c='k',s=40,alpha=.5,edgecolor='None')\n",
    "for n in range(len(timescales_As)):\n",
    "    ax.axvline(x=timescales_As[n],c=sys_clrs[clr_ind[n]])\n",
    "    ax.scatter(x=timescales_As[n],y=np.abs(evals_As[n]),\n",
    "            c=sys_clrs[clr_ind[n]],s=40,alpha=1,edgecolor='None')\n",
    "ax.set_xscale('symlog',linthresh=.1)\n",
    "ax.set_yticks([0,.5,1])\n",
    "ax.set_ylim(0,1.1)\n",
    "# ax.set_yticks([np.diff(y_ranges)[0,0]/2 + q*dts for q in range(len(np.unique(full_state_z)))])\n",
    "# ax.set_yticklabels([''.join(lst2[n]) for n in range(len(lst2))],fontsize=fontsize-2)\n",
    "# ax.set_xticks([0,-10e0,-10e-1])\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2)\n",
    "ax.set_ylabel('|$\\lambda$|',fontsize=fontsize)\n",
    "y = 1\n",
    "dy = 0.15\n",
    "ax.annotate('system 1', xy=(.01,y),xycoords='axes fraction',color=sys_clrs[clr_ind[0]],fontsize=fontsize-3.5)\n",
    "ax.annotate('system 2', xy=(.01,y-dy),xycoords='axes fraction',color=sys_clrs[clr_ind[2]],fontsize=fontsize-3.5)\n",
    "ax.annotate('system 3', xy=(.01,y-2*dy),xycoords='axes fraction',color=sys_clrs[clr_ind[4]],fontsize=fontsize-3.5)\n",
    "# ax.set_xticks([0,-10e0,-10e-1])\n",
    "ax.set_xlabel('timescales',fontsize=fontsize,labelpad=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd0f76",
   "metadata": {},
   "source": [
    "# Load Anymal Terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ffe840",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'AnymalTerrain'\n",
    "base_dir = Path('/data/users/eabe/hypernets/{}/TiDHy_{}/'.format(dataset,dataset))\n",
    "configs = sorted(list(base_dir.rglob('*config.yaml'))[::2])\n",
    "\n",
    "for n,conf in enumerate(configs):\n",
    "    print(n,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3dfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "default_model_config = '/home/eabe/Research/MyRepos/HyperNets/conf/dataset/model/default_model.yaml'\n",
    "params = OmegaConf.load(default_model_config)\n",
    "cfg_path =configs[n]# Path('/data/users/eabe/hypernets/SLDS/DPC_SLDS/TestingNoTempLearning/mix_dim=15/config.yaml')\n",
    "cfg = OmegaConf.load(cfg_path)\n",
    "for k in cfg.paths.keys():\n",
    "    cfg.paths[k] = Path(cfg.paths[k])\n",
    "    cfg.paths[k].mkdir(parents=True, exist_ok=True)\n",
    "params_curr = cfg.dataset.model\n",
    "cfg.dataset.model = OmegaConf.merge(params, params_curr)\n",
    "cfg.dataset.train.normalize_obs = False\n",
    "cfg.model.batch_converge=False\n",
    "cfg.model.Orth_alpha_spat = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238228b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict, cfg = load_dataset(cfg)\n",
    "# ##### Convert to float tensors #####\n",
    "train_inputs = torch.tensor(data_dict['inputs_train']).float()\n",
    "test_inputs = torch.tensor(data_dict['inputs_test']).float()\n",
    "\n",
    "input_dim = train_inputs.shape[-1]\n",
    "\n",
    "train_inputs = train_inputs.reshape(-1, cfg.train.sequence_length, input_dim)\n",
    "test_inputs = test_inputs.reshape(-1, cfg.train.sequence_length, input_dim)\n",
    "cfg.model.input_dim = input_dim\n",
    "\n",
    "if cfg.train.batch_size_input:\n",
    "    batch_size_train = train_inputs.shape[0]\n",
    "    batch_size_test = test_inputs.shape[0]\n",
    "else:\n",
    "    batch_size_train = cfg.train.batch_size\n",
    "    # batch_size_test = cfg.train.batch_size\n",
    "    batch_size_test = test_inputs.shape[0]\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_inputs)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_inputs)\n",
    "dataloader_train = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size_train,pin_memory=True,shuffle=True,drop_last=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size_test,pin_memory=True,drop_last=True)\n",
    "device = torch.device(\"cuda:{}\".format(cfg.train['gpu']) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Load weights and params #####\n",
    "rerecord = False\n",
    "epoch = 1000\n",
    "model = TiDHy.TiDHy(cfg.model, device, show_progress=cfg.train.show_progress).to(device)\n",
    "# set_seed(42)\n",
    "load_path = cfg.paths.ckpt_dir/'best.pth.tar'\n",
    "load_path = sorted(list(cfg.paths.ckpt_dir.rglob('last_{}.pth.tar'.format(epoch))))[0]\n",
    "data_load = torch.load(load_path,map_location=device)\n",
    "model.load_state_dict(data_load['state_dict'])\n",
    "model.to(device)\n",
    "print('Loaded from {} epoch'.format(data_load['epoch']))\n",
    "epoch = data_load['epoch']\n",
    "\n",
    "\n",
    "# result_dict = load_results(model, dataloader_test, data_dict, device, cfg, epoch, rerecord=rerecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "fontsize=13\n",
    "\n",
    "clrs = np.array(['#1A237E','#7E57C2','#757575','#BDBDBD','#4CAF50','#FF9800','#795548','#FF4081','#00BCD4','#FF1744','#FFFFFF','#000000'])\n",
    "sys_clrs = ['#E3A19F','#E3BE53','#708090','#90CCA9','#B7522E','#B0E0E6','#A89AC2','#556B2F','#FF6F61','#87CEEB','#FFDAB9','#40E0D0']\n",
    "cmap_sys = ListedColormap(sys_clrs)\n",
    "clr_ind =[2,2,8,8,9,9]\n",
    "# clr2 = [sys_clrs[clr_ind[n]] for n in range(len(clr_ind))]\n",
    "clr_ind3 = [2,8,9]\n",
    "clr2b = [sys_clrs[clr_ind3[n]] for n in range(len(clr_ind3))]\n",
    "\n",
    "clrs_b = clrs[[0,1,2,9,4,6,7,8,11]]\n",
    "cmap = ListedColormap(clrs)\n",
    "# cmap_small = ListedColormap(clrs[:len(np.unique(full_state_z))])\n",
    "cmap_b = ListedColormap(clrs_b)\n",
    "cmap\n",
    "# cmap_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b51ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = [100,200,500,1000]\n",
    "\n",
    "cfg, result_dict = run_seq_len_model(seq_len, model, data_dict, device, epoch, cfg, rerun=False)\n",
    "\n",
    "data_dict, cfg = load_dataset(cfg)\n",
    "seq_len = sorted([int(el) for el in list(result_dict.keys())])\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_figs = False\n",
    "ts=-2\n",
    "W = result_dict['{}'.format(seq_len[ts])]['W'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['W'].shape[-1])\n",
    "# b = result_dict['b'].reshape(-1,result_dict['b'].shape[-1])\n",
    "I = result_dict['{}'.format(seq_len[ts])]['I'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I'].shape[-1])\n",
    "Ihat = result_dict['{}'.format(seq_len[ts])]['I_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I_hat'].shape[-1])\n",
    "Ibar = result_dict['{}'.format(seq_len[ts])]['I_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I_bar'].shape[-1])\n",
    "R_hat = result_dict['{}'.format(seq_len[ts])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_hat'].shape[-1])\n",
    "R_bar = result_dict['{}'.format(seq_len[ts])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_bar'].shape[-1])\n",
    "R2_hat = result_dict['{}'.format(seq_len[ts])]['R2_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R2_hat'].shape[-1])\n",
    "# Ut = result_dict['Ut'].reshape(-1,result_dict['Ut'].shape[-2],result_dict['Ut'].shape[-1])\n",
    "# ##### Plot dynamic matrices #####\n",
    "if cfg.model.low_rank_temp:\n",
    "    Uk = torch.bmm(model.temporal.unsqueeze(-1),model.temporal.unsqueeze(1)).data.cpu().detach()\n",
    "else:\n",
    "    Uk = model.temporal.data.cpu().detach().reshape(model.mix_dim,model.r_dim,model.r_dim)\n",
    "    U_t = torch.matmul(torch.Tensor(W[:,None,:]), model.temporal.unsqueeze(0).cpu().detach()).reshape(-1, model.r_dim, model.r_dim).numpy()\n",
    "\n",
    "nfig = 0\n",
    "t = 0; dt = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50825e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "t=0; dt=1000\n",
    "spacing= .1\n",
    "ts=-2\n",
    "I = result_dict['{}'.format(seq_len[ts])]['I'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I'].shape[-1])\n",
    "I_shuff  = deepcopy(result_dict['{}'.format(seq_len[ts])]['I'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I'].shape[-1]))\n",
    "Ihat = result_dict['{}'.format(seq_len[ts])]['I_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I_hat'].shape[-1])\n",
    "# fig,axs = plt.subplots(1,2,figsize=(5,3),sharey=True,gridspec_kw={'wspace':.15,'width_ratios':[2,1]})\n",
    "fig,axs = plt.subplots(1,2,figsize=(8,5))\n",
    "ax = axs[0]\n",
    "# cmap,norm = map_discrete_cbar(cmap,len(np.unique(full_state_z)))\n",
    "hlines_I,hlines_Ihat = [],[]\n",
    "for n in range(I.shape[-1]):\n",
    "    mean_centered_I = I[t:t+dt,n] - np.mean(I[t:t+dt,n],axis=0)\n",
    "    ax.plot(mean_centered_I + n/spacing,color='k', lw=1,zorder=1,label='Data')\n",
    "    hlines_I.append(np.mean(mean_centered_I + n/spacing,axis=0))\n",
    "    mean_centered_Ihat = Ihat[t:t+dt,n] - np.mean(Ihat[t:t+dt,n],axis=0)\n",
    "    ax.plot(mean_centered_Ihat + n/spacing,ls='-',color='#4e7eb3ff', lw=1,zorder=2,label='Pred')\n",
    "    hlines_Ihat.append(np.mean(mean_centered_Ihat + n/spacing,axis=0))\n",
    "# X,Y = np.meshgrid(np.arange(0,dt),np.arange(-1,2*I.shape[-1]))\n",
    "# im = ax.pcolormesh(X,Y,np.tile(full_state_z[None,t:t+dt],(2*I.shape[-1]+1,1)),cmap=cmap,norm=norm,alpha=.5,rasterized=True,zorder=-1)\n",
    "# # im = ax.pcolormesh(X,Y,np.tile(full_state_z[None,t:t+dt],(2*I.shape[-1],1)),cmap=cmap,norm=norm,alpha=.5)\n",
    "# cbar = fig.colorbar(im,ax=axs,aspect=30)\n",
    "# cbar.set_ticks(np.arange(.5,len(np.unique(full_state_z)),1))\n",
    "# cbar.set_ticklabels([''.join(lst2[n]) for n in range(len(lst2))],fontsize=fontsize)\n",
    "# cbar.outline.set_linewidth(1)\n",
    "# cbar.minorticks_off()\n",
    "# cbar.ax.tick_params(width=1,which=\"major\")\n",
    "\n",
    "ax.set_yticks(hlines_I)\n",
    "ax.set_yticklabels(np.arange(1,len(hlines_I)+1),fontsize=fontsize)\n",
    "# ax.set_xticklabels(np.arange(0,1200,200),fontsize=fontsize)\n",
    "ax.set_xlabel('Timesteps',fontsize=fontsize)\n",
    "ax.set_ylabel('Observation #',fontsize=fontsize)\n",
    "ax.legend(['data','pred'],frameon=False,fontsize=fontsize,loc='upper right',bbox_to_anchor=(1.025,1.05),labelcolor='linecolor',handlelength=0,handleheight=0,ncols=2,columnspacing=.1)\n",
    "\n",
    "# ax.set_title('Learned Observations',fontsize=fontsize)\n",
    "lim0 = 0\n",
    "lim1 = 20\n",
    "hbins = 1\n",
    "Input_Errors = np.mean((I-Ihat)**2,axis=0)\n",
    "# Input_Errors_SLDS = np.mean((inputs_test_SLDS-q_lem_y)**2,axis=0)\n",
    "I_shuff = shuffle_along_axis(I_shuff,axis=1)\n",
    "Input_Errors_shuff = np.mean((I_shuff-Ihat)**2,axis=0)\n",
    "ax = axs[1]\n",
    "count,edges = np.histogram(Input_Errors,bins=np.arange(lim0,lim1,hbins))\n",
    "edges_mid = np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "ax.bar(edges_mid, count/len(Input_Errors),color='#757575ff',width=hbins, alpha=1,zorder=1,label='data')\n",
    "count,edges = np.histogram(Input_Errors_shuff,bins=np.arange(lim0,lim1,hbins))\n",
    "edges_mid = np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "ax.bar(edges_mid, count/len(Input_Errors),color='r',width=hbins, alpha=1,zorder=1,label='shuffle') \n",
    "# count,edges = np.histogram(Input_Errors_SLDS,bins=np.arange(lim0,lim1,hbins))\n",
    "# edges_mid = np.array([(edges[i]+edges[i+1])/2 for i in range(len(edges)-1)])\n",
    "# ax.bar(edges_mid, count/len(Input_Errors_SLDS),color='g',width=hbins, alpha=.5,zorder=1,label='SLDS') \n",
    "ax.set_ylabel('Proportion',fontsize=fontsize)\n",
    "ax.set_xlabel('MSE',fontsize=fontsize)\n",
    "ax.legend(frameon=False,fontsize=fontsize)\n",
    "# ax = axs[1]\n",
    "# fig,axs = plt.subplots(1,1,figsize=(4,4))\n",
    "# Input_Errors = np.mean((I-Ihat)**2,axis=0)\n",
    "# I_shuff = shuffle_along_axis(I_shuff,axis=1)\n",
    "# Input_Errors_shuff = np.mean((I_shuff-Ihat)**2,axis=0)\n",
    "# xs = np.arange(I.shape[-1])\n",
    "# heights = Input_Errors\n",
    "# ax.barh(y=hlines_I,width=heights,color='k',)\n",
    "# ax.errorbar(heights,hlines_I,xerr=np.std((I-Ihat),axis=0)/np.sqrt((I-Ihat).shape[0]),ls='none',color='tab:gray',capsize=3)\n",
    "# ax.axvline(x=np.mean(Input_Errors_shuff),c='k',ls='--',lw=1,label='shuffle error')\n",
    "# # ax.set_xticks(np.arange(0,.004,.001))\n",
    "# ax.set_xlabel('MSE',fontsize=fontsize)\n",
    "# ax.set_title('Average Error',fontsize=fontsize)\n",
    "# ax.set_xticklabels(np.arange(heights.shape[-1])+1)\n",
    "# ax.legend(bbox_to_anchor=(.3, .95), loc='lower left', borderaxespad=0.,frameon=False,fontsize=fontsize)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(cfg.paths.fig_dir/'{}_observations_pred.png'.format(nfig),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55efab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 2\n",
    "t=0; dt = 1000\n",
    "# cmap2,norm = map_discrete_cbar(cmap,len(np.unique(full_state_z)))\n",
    "fig, axs = plt.subplots(2,2,figsize=(20,12))\n",
    "axs = axs.flatten()\n",
    "fontsize=13\n",
    "ax = axs[0]\n",
    "spacing= 1.5\n",
    "for p in range(len(seq_len)):\n",
    "    hlines_x = []\n",
    "    for n in range(result_dict['{}'.format(seq_len[p])]['R2_hat'].shape[-1]):\n",
    "        trace = result_dict['{}'.format(seq_len[p])]['R2_hat'][t:t+dt,n]\n",
    "        mean_centered_x = trace - np.mean(trace,axis=0)\n",
    "        ax.plot(mean_centered_x + n/spacing, lw=1,zorder=1,c=clrs_b[p],alpha=.5)\n",
    "        hlines_x.append(np.mean(mean_centered_x + n/spacing,axis=0))\n",
    "ax.set_yticks(hlines_x)\n",
    "ax.set_yticklabels(np.arange(1,len(hlines_x)+1),fontsize=fontsize-2)\n",
    "ax.set_xticks(np.arange(0,t+dt+dt//4,(t+dt)//4))\n",
    "ax.set_xticklabels(np.arange(0,t+dt+dt//4,(t+dt)//4),fontsize=fontsize-2)\n",
    "X,Y = np.meshgrid(np.arange(0,dt),np.arange(-.5,.75,.25))\n",
    "# im = ax.pcolormesh(X,Y,np.tile(full_state_z[None,t:t+dt],(Y.shape[0],1)),cmap=cmap,norm=norm,alpha=.5,rasterized=True,zorder=-1)\n",
    "ax.set_ylabel('$\\hat{r}^h$',fontsize=fontsize)\n",
    "ax.set_xlabel('time',fontsize=fontsize)\n",
    "ax.legend(['T={}'.format(Ln) for Ln in seq_len],frameon=False,fontsize=fontsize,loc='upper right',bbox_to_anchor=(1.15,1.05),labelcolor=clrs_b,handlelength=0,handleheight=0,ncols=1,columnspacing=.1)\n",
    "\n",
    "ax = axs[1]\n",
    "spacing= 1.5\n",
    "for p in range(len(seq_len)):\n",
    "    hlines_x = []\n",
    "    for n in range(result_dict['{}'.format(seq_len[p])]['W'].shape[-1]):\n",
    "        trace = result_dict['{}'.format(seq_len[p])]['W'][t:t+dt,n]\n",
    "        mean_centered_x = trace - np.mean(trace,axis=0)\n",
    "        ax.plot(mean_centered_x + n/spacing, lw=1,zorder=1,c=clrs_b[p],alpha=.5)\n",
    "        hlines_x.append(np.mean(mean_centered_x + n/spacing,axis=0))\n",
    "ax.set_xticks(np.arange(0,t+dt+dt//4,(t+dt)//4))\n",
    "ax.set_xticklabels(np.arange(0,t+dt+dt//4,(t+dt)//4),fontsize=fontsize-2)\n",
    "ax.set_yticks(hlines_x)\n",
    "ax.set_yticklabels(np.arange(1,len(hlines_x)+1),fontsize=fontsize-2)\n",
    "X,Y = np.meshgrid(np.arange(0,dt),np.arange(0,2.25,.25))\n",
    "# im = ax.pcolormesh(X,Y,np.tile(full_state_z[None,t:t+dt],(Y.shape[0],1)),cmap=cmap,norm=norm,alpha=.5,rasterized=True,zorder=-1)\n",
    "ax.set_ylabel('W',fontsize=fontsize)\n",
    "ax.set_xlabel('time',fontsize=fontsize)\n",
    "ax = axs[2]\n",
    "ax.set_ylabel('$\\hat{r}$',fontsize=fontsize)\n",
    "ax.set_xlabel('time',fontsize=fontsize)\n",
    "spacing= 1.5\n",
    "for p in range(len(seq_len)):\n",
    "    hlines_x = []\n",
    "    for n in range(result_dict['{}'.format(seq_len[p])]['R_bar'].shape[-1]):\n",
    "        trace = result_dict['{}'.format(seq_len[p])]['R_bar'][t:t+dt,n]\n",
    "        mean_centered_x = trace - np.mean(trace,axis=0)\n",
    "        ax.plot(mean_centered_x + n/spacing, lw=1,zorder=1,c=clrs_b[p],alpha=.5)\n",
    "        hlines_x.append(np.mean(mean_centered_x + n/spacing,axis=0))\n",
    "ax.set_xticks(np.arange(0,t+dt+dt//4,(t+dt)//4))\n",
    "ax.set_xticklabels(np.arange(0,t+dt+dt//4,(t+dt)//4),fontsize=fontsize-2)\n",
    "ax.set_yticks(hlines_x)\n",
    "ax.set_yticklabels(np.arange(1,len(hlines_x)+1),fontsize=fontsize-2)\n",
    "\n",
    "ax = axs[3]\n",
    "spacing= 1\n",
    "for p in range(len(seq_len)):\n",
    "    hlines_x = []\n",
    "    for n in range(result_dict['{}'.format(seq_len[p])]['I_hat'].shape[-1]):\n",
    "        trace = result_dict['{}'.format(seq_len[p])]['I_hat'][t:t+dt,n]\n",
    "        mean_centered_x = trace - np.mean(trace,axis=0)\n",
    "        ax.plot(mean_centered_x + n/spacing, lw=1,zorder=1,c=clrs_b[p],alpha=.5)\n",
    "        hlines_x.append(np.mean(mean_centered_x + n/spacing,axis=0))\n",
    "for n in range(result_dict['{}'.format(seq_len[p])]['I_hat'].shape[-1]):\n",
    "    trace = result_dict['{}'.format(seq_len[p])]['I'][t:t+dt,n]\n",
    "    mean_centered_x = trace - np.mean(trace,axis=0)\n",
    "    ax.plot(mean_centered_x + n/spacing, lw=1,zorder=1,c=clrs_b[-1],alpha=.5)\n",
    "ax.set_xticks(np.arange(0,t+dt+dt//4,(t+dt)//4))\n",
    "ax.set_xticklabels(np.arange(0,t+dt+dt//4,(t+dt)//4),fontsize=fontsize-2)\n",
    "ax.set_yticks(hlines_x)\n",
    "ax.set_yticklabels(np.arange(1,len(hlines_x)+1),fontsize=fontsize-2)\n",
    "ax.set_ylabel('$\\hat{Z}$',fontsize=fontsize)\n",
    "ax.set_xlabel('time',fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "# fig.savefig(cfg.paths.fig_dir/'{}_TempWindExpansion.png'.format(nfig),dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1073bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_clrs = ['#E3A19F','#E3BE53','#708090','#90CCA9','#B7522E','#B0E0E6','#A89AC2','#556B2F','#FF6F61','#87CEEB','#FFDAB9','#40E0D0']\n",
    "cmap_sys = ListedColormap(sys_clrs)\n",
    "clr_ind = [2,8,9]\n",
    "clr2 = [sys_clrs[clr_ind[n]] for n in range(len(clr_ind))]\n",
    "terrain_names = ['Flat','Slope','Inv. Slope','Stairs','Inv. Stairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain_type_train = data_dict['terrain_train'].reshape(-1)\n",
    "terrain_type_test = data_dict['terrain_test']\n",
    "terrain_difficulty_train = data_dict['terrain_difficulty_train'].reshape(-1)\n",
    "terrain_difficulty_test = data_dict['terrain_difficulty_test'].reshape(-1)\n",
    "terrain_slope_train = data_dict['terrain_slope_train'].reshape(-1)\n",
    "terrain_slope_test = data_dict['terrain_slope_test'].reshape(-1)\n",
    "command_vel_train = data_dict['command_vel_train'].reshape(-1)\n",
    "command_vel_test = data_dict['command_vel_test'].reshape(-1)\n",
    "\n",
    "robot_type_test = data_dict['robot_type_test']\n",
    "terrain_robot_test = np.stack([terrain_type_test[robot_type_test==0].reshape(-1),terrain_type_test[robot_type_test==1].reshape(-1)])\n",
    "terrain_type_test = data_dict['terrain_test'].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59828be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1,figsize=(4,4))\n",
    "seq_len=[100,200,500,1000]\n",
    "ax = axs\n",
    "dts = 1/len(seq_len)\n",
    "# timescales_M = 1/np.abs(np.real(np.log(np.linalg.eigvals(M))))[1:]\n",
    "y_ranges = np.arange(0,1,(dts*dts)).reshape(-1,len(seq_len))[:,(0,-1)]\n",
    "for ts in range(len(seq_len)):\n",
    "    # R_bar = result_dict['{}'.format(seq_len[ts])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_bar'].shape[-1])\n",
    "    R_hat = result_dict['{}'.format(seq_len[ts])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_hat'].shape[-1])\n",
    "    R2_hat = result_dict['{}'.format(seq_len[ts])]['R2_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R2_hat'].shape[-1])\n",
    "    I = result_dict['{}'.format(seq_len[ts])]['I'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I'].shape[-1])\n",
    "\n",
    "    # ##### Plottign Eigenvalues #####\n",
    "    Uhat_all = []\n",
    "    for p in range(terrain_robot_test.shape[0]):\n",
    "        for state in range(len(np.unique(terrain_type_test))):\n",
    "            rhat2 = R_hat[np.where(terrain_robot_test[p]==state)[0],:]\n",
    "            Uhat_0 = np.linalg.inv(rhat2[:-1].T@rhat2[:-1])@rhat2[:-1].T@rhat2[1:]\n",
    "            Uhat_all.append(Uhat_0)\n",
    "            # eig_Ut = np.linalg.eigvals(Uhat_0).reshape(-1)\n",
    "            # timescales = np.real(np.log(eig_Ut))\n",
    "    Uhat_all = np.stack(Uhat_all)\n",
    "    evals_Uhat_all = np.linalg.eigvals(Uhat_all).reshape(-1)\n",
    "    timescales = np.real(np.log(evals_Uhat_all))\n",
    "\n",
    "    ax.scatter(x=1/np.abs(timescales),y=np.random.uniform(y_ranges[ts,0],y_ranges[ts,1],timescales.shape[0]),\n",
    "            c=clrs_b[ts],alpha=.5,edgecolor='None')\n",
    "\n",
    "# for n in range(len(timescales_M)):\n",
    "#     ax.axvline(x=timescales_M[n],c=sys_clrs[n])\n",
    "ax.set_xscale('symlog',linthresh=10)\n",
    "ax.set_yticks([np.diff(y_ranges)[0,0]/2 + q*dts for q in range(len(seq_len))])\n",
    "ax.set_yticklabels(seq_len,fontsize=fontsize)\n",
    "ax.set_ylabel('T',fontsize=fontsize)\n",
    "# ax.spines.left.set_visible(False)\n",
    "ax.set_xlabel('timescales',fontsize=fontsize)\n",
    "ax.set_xticks([0,10e0,10e1])\n",
    "ax.tick_params(axis='x', labelsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "ts=-2\n",
    "# nani = terrain.shape[0]\n",
    "# reg_variables = [np.concatenate([result_dict['R2_hat'],result_dict['W'],result_dict['R_bar']],axis=-1),result_dict['R2_hat'],result_dict['W'],result_dict['R_hat'],result_dict['I']]\n",
    "reg_variables = [result_dict['{}'.format(seq_len[ts])]['R2_hat'],result_dict['{}'.format(seq_len[ts])]['I']]\n",
    "labels = ['R2_hat','I']\n",
    "# labels = ['all','R2_hat','W','R_hat','I']\n",
    "robot_type_test = data_dict['robot_type_test']\n",
    "robot_type_test=np.tile(robot_type_test,(9000,1)).transpose(1,0)\n",
    "command_vel_test = np.tile(robot_type_test,(9000,1)).transpose(1,0)\n",
    "# reg_variables = W\n",
    "max_acc = 0\n",
    "tr_batch_size = 40\n",
    "batch_size = 10\n",
    "for k,reg_vars in enumerate(reg_variables):\n",
    "    # X_train = reg_vars[:tr_batch_size].reshape(-1,reg_vars.shape[-1])\n",
    "    # X_test = reg_vars[-batch_size:].reshape(-1,reg_vars.shape[-1])\n",
    "    # y_train = terrain[:tr_batch_size].reshape(-1)\n",
    "    # y_test = terrain[-batch_size:].reshape(-1)\n",
    "    # y_train = robot_type_test[:tr_batch_size].reshape(-1)\n",
    "    # y_test = robot_type_test[-batch_size:].reshape(-1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reg_vars.reshape(-1,reg_vars.shape[-1]), terrain_type_test.reshape(-1), test_size=0.25, random_state=42)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(reg_vars.reshape(-1,reg_vars.shape[-1]), robot_type_test.reshape(-1), test_size=0.25, random_state=42)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "    # neigh = RidgeClassifierCV()\n",
    "    neigh.fit(X_train, y_train)\n",
    "    # y_pred = neigh.predict(X_test)\n",
    "    scores = neigh.score(X_test, y_test)\n",
    "    print(labels[k],scores)\n",
    "    if (scores > max_acc) & (labels[k] != 'I'):\n",
    "        y_pred = neigh.predict(reg_vars.reshape(-1,reg_vars.shape[-1]))\n",
    "        max_acc = scores\n",
    "        best_reg_vars = reg_vars\n",
    "        best_label = labels[k]\n",
    "        best_pred_terrain = y_pred\n",
    "    else:\n",
    "        I_pred = neigh.predict(reg_vars.reshape(-1,reg_vars.shape[-1]))\n",
    "        \n",
    "state_compare = np.stack([I_pred,best_pred_terrain,terrain_type_test])\n",
    "# plt.imshow(confusion_matrix(full_state_z, y_pred),cmap='viridis')\n",
    "# plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded530d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_type_test.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518a7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier,LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# nani = terrain.shape[0]\n",
    "# reg_variables = [np.concatenate([R2_hat,W,R_bar],axis=-1),R2_hat,W,R_hat,I]\n",
    "# labels = ['all','R2_hat','W','R_hat','I']\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(I.reshape(-1,I.shape[-1]))\n",
    "reg_variables = [R2_hat,I] #,X_pca]\n",
    "labels = ['R2_hat','I'] #,'X_pca']\n",
    "label_type = ['terrain_difficulty_test','terrain_slope_test','command_vel_test']#,'robot_type_test']\n",
    "\n",
    "robot_type_test = data_dict['robot_type_test']\n",
    "robot_type_test=np.tile(robot_type_test,(9000,1)).transpose(1,0).reshape(-1)\n",
    "command_vel_test = np.tile(data_dict['command_vel_test'],(9000,1)).transpose(1,0)\n",
    "slope_cat = np.unique(terrain_slope_test,return_inverse=True)[1]\n",
    "difficulty_cat =  np.unique(terrain_difficulty_test,return_inverse=True)[1]\n",
    "vel_cat = np.unique(command_vel_test,return_inverse=True)[1]\n",
    "# reg_variables = W\n",
    "max_acc = 0\n",
    "tr_batch_size = 40\n",
    "batch_size = 10\n",
    "class_results = {}\n",
    "state_compare_best = {}\n",
    "for m, test_labels in enumerate([difficulty_cat,slope_cat,vel_cat]): #,robot_type_test\n",
    "\n",
    "    for k,reg_vars in enumerate(reg_variables):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(reg_vars.reshape(-1,reg_vars.shape[-1]), test_labels.reshape(-1), test_size=0.25, random_state=42)\n",
    "\n",
    "        neigh = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "        neigh.fit(X_train, y_train)\n",
    "        scores = neigh.score(X_test, y_test)\n",
    "        print(label_type[m],labels[k],scores)\n",
    "        if (labels[k] != 'I'):\n",
    "            y_pred = neigh.predict(reg_vars.reshape(-1,reg_vars.shape[-1]))\n",
    "            class_results['{}_{}_pred'.format(label_type[m],labels[k])] = y_pred\n",
    "            class_results['{}_{}_score'.format(label_type[m],labels[k])] = scores\n",
    "            max_acc = scores\n",
    "            best_reg_vars = reg_vars\n",
    "            best_label = labels[k]\n",
    "            best_pred = y_pred\n",
    "        else:\n",
    "            I_pred = neigh.predict(reg_vars.reshape(-1,reg_vars.shape[-1]))\n",
    "            class_results['{}_{}_pred'.format(label_type[m],labels[k])] = I_pred\n",
    "            class_results['{}_{}_score'.format(label_type[m],labels[k])] = scores\n",
    "    state_compare_best['{}'.format(label_type[m])] = np.stack([I_pred,best_pred,test_labels],axis=0)\n",
    "\n",
    "# plt.imshow(confusion_matrix(full_state_z, y_pred),cmap='viridis')\n",
    "# plt.colorbar()\n",
    "from sklearn import metrics\n",
    "f1_TiDHy = [metrics.f1_score(state_compare_best[key][-1],state_compare_best[key][1],average='weighted') for key in state_compare_best.keys()]\n",
    "f1_Inputs = [metrics.f1_score(state_compare_best[key][-1],state_compare_best[key][0],average='weighted') for key in state_compare_best.keys()]\n",
    "clrs2 =['#0F4C5C','#F4D03F','#FF6B6B','#2E8B57','#87CEEB','#778899','#40E0D0','#FFDB58','#4169E1','#C2B280','#FFDAB9','#000080','#556B2F','#008080','#FFFDD0','#B7410E','#6A5ACD','#FFBF00','#FFD1DC','#800080','#98FF98','#FA8072','#E6E6FA','#36454F']\n",
    "cmap2 = ListedColormap(clrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bafde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_compare_data = {'state_compare_best':state_compare_best,'state_compare':state_compare,'class_results':class_results}\n",
    "ioh5.save(cfg.paths.log_dir/'state_compare.h5',state_compare_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e59514",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_compare_data = ioh5.load(cfg.paths.log_dir/'state_compare.h5')\n",
    "state_compare = state_compare_data['state_compare']\n",
    "state_compare_best = state_compare_data['state_compare_best']\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "f1_TiDHy = [metrics.f1_score(state_compare_best[key][-1],state_compare_best[key][1],average='weighted') for key in state_compare_best.keys()]\n",
    "f1_Inputs = [metrics.f1_score(state_compare_best[key][-1],state_compare_best[key][0],average='weighted') for key in state_compare_best.keys()]\n",
    "clrs2 =['#0F4C5C','#F4D03F','#FF6B6B','#2E8B57','#87CEEB','#778899','#40E0D0','#FFDB58','#4169E1','#C2B280','#FFDAB9','#000080','#556B2F','#008080','#FFFDD0','#B7410E','#6A5ACD','#FFBF00','#FFD1DC','#800080','#98FF98','#FA8072','#E6E6FA','#36454F']\n",
    "cmap2 = ListedColormap(clrs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=2500; dt=1000\n",
    "fontsize=13\n",
    "fig = plt.figure(constrained_layout=True, figsize=(7.75,5.5))\n",
    "gs0 = gridspec.GridSpec(nrows=6,ncols=3, figure=fig, wspace=.1,hspace=.1)\n",
    "\n",
    "gs00 = gridspec.GridSpecFromSubplotSpec(nrows=1,ncols=5, subplot_spec=gs0[:3,:],wspace=.1,hspace=.1)\n",
    "gs01 = gridspec.GridSpecFromSubplotSpec(nrows=1,ncols=5,subplot_spec=gs0[4:,:],wspace=.1,hspace=.2)\n",
    "axs = np.array([fig.add_subplot(gs00[:,:2]),\n",
    "                fig.add_subplot(gs00[:,2:4]),\n",
    "                fig.add_subplot(gs00[:,4:]),\n",
    "                fig.add_subplot(gs01[:,:2]),\n",
    "                fig.add_subplot(gs01[:,2:])])\n",
    "ax = axs[1]\n",
    "spacing= .5\n",
    "for n in range(result_dict['{}'.format(seq_len[ts])]['I_hat'].shape[-1]):\n",
    "    trace = result_dict['{}'.format(seq_len[ts])]['I'][t:t+dt,n]\n",
    "    mean_centered_x = (trace - np.mean(trace,axis=0))/np.max(np.abs(trace))\n",
    "    ax.plot(mean_centered_x + n/spacing, lw=1,zorder=1,c=clrs_b[-1],alpha=1)\n",
    "ts=1\n",
    "hlines_x = []\n",
    "for n in range(result_dict['{}'.format(seq_len[ts])]['I_hat'].shape[-1]):\n",
    "    trace = result_dict['{}'.format(seq_len[ts])]['I_hat'][t:t+dt,n]\n",
    "    mean_centered_x = (trace - np.mean(trace,axis=0))/np.max(np.abs(trace))\n",
    "    ax.plot(mean_centered_x + n/spacing, lw=1,zorder=1,c='r',alpha=.75)\n",
    "    hlines_x.append(np.mean(mean_centered_x + n/spacing,axis=0))\n",
    "# ax.set_xticks(np.arange(0,t+dt+dt//4,(t+dt)//4))\n",
    "# ax.set_xticklabels(np.arange(0,t+dt+dt//4,(t+dt)//4),fontsize=fontsize-2)\n",
    "# ax.set_yticks(hlines_x[1::2])\n",
    "ax.set_yticks([])\n",
    "# ax.set_yticklabels(np.arange(2,len(hlines_x)+1,2),fontsize=fontsize-2)\n",
    "ax.set_ylabel('observations',fontsize=fontsize)\n",
    "ax.set_xlabel('timesteps',fontsize=fontsize)\n",
    "# ax.set_ylim(-1,(1/spacing)*len(hlines_x)+.5)\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2)\n",
    "\n",
    "\n",
    "ax = axs[2]\n",
    "dts = 1/len(seq_len)\n",
    "# timescales_M = 1/np.abs(np.real(np.log(np.linalg.eigvals(M))))[1:]\n",
    "y_ranges = np.arange(0,1,(dts*dts)).reshape(-1,len(seq_len))[:,(0,-1)]\n",
    "for ts in range(len(seq_len)):\n",
    "    # R_bar = result_dict['{}'.format(seq_len[ts])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_bar'].shape[-1])\n",
    "    R_hat = result_dict['{}'.format(seq_len[ts])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_hat'].shape[-1])\n",
    "    R2_hat = result_dict['{}'.format(seq_len[ts])]['R2_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R2_hat'].shape[-1])\n",
    "    I = result_dict['{}'.format(seq_len[ts])]['I'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I'].shape[-1])\n",
    "\n",
    "    # ##### Plottign Eigenvalues #####\n",
    "    Uhat_all = []\n",
    "    for p in range(terrain_robot_test.shape[0]):\n",
    "        for state in range(len(np.unique(terrain_type_test))):\n",
    "            rhat2 = R_hat[np.where(terrain_robot_test[p]==state)[0],:]\n",
    "            Uhat_0 = np.linalg.inv(rhat2[:-1].T@rhat2[:-1])@rhat2[:-1].T@rhat2[1:]\n",
    "            Uhat_all.append(Uhat_0)\n",
    "            # eig_Ut = np.linalg.eigvals(Uhat_0).reshape(-1)\n",
    "            # timescales = np.real(np.log(eig_Ut))\n",
    "    Uhat_all = np.stack(Uhat_all)\n",
    "    evals_Uhat_all = np.linalg.eigvals(Uhat_all).reshape(-1)\n",
    "    timescales = np.real(np.log(evals_Uhat_all))\n",
    "\n",
    "    ax.scatter(x=1/np.abs(timescales),y=np.abs(evals_Uhat_all)+ts,\n",
    "            c=clrs_b[ts],alpha=.5,edgecolor='None',s=25)\n",
    "\n",
    "for ts in range(len(seq_len)):\n",
    "    ax.axhline(y=ts,c=clrs_b[ts],linestyle='--',zorder=-1)\n",
    "#     ax.axvline(x=timescales_M[n],c=sys_clrs[n])\n",
    "ax.set_xscale('symlog',linthresh=10)\n",
    "ax.set_yticks([1/2 + q for q in range(len(seq_len))])\n",
    "ax.set_yticklabels(seq_len,fontsize=fontsize-2)\n",
    "ax.set_ylabel('T',fontsize=fontsize,labelpad=-5)\n",
    "# ax.spines.left.set_visible(False)\n",
    "ax.set_xlabel('timescales',fontsize=fontsize,labelpad=-2)\n",
    "ax.set_xticks([0,10e0,10e1,10e2])\n",
    "ax.set_xlim(0,1e2)\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2, pad=-1)\n",
    "\n",
    "\n",
    "ax=axs[3]\n",
    "ax.bar(np.arange(len(f1_TiDHy)),f1_TiDHy,width=.4,color=clrs2[0])\n",
    "ax.bar(np.arange(len(f1_Inputs))+.4,f1_Inputs,width=.4,color=clrs2[4])\n",
    "ax.set_ylabel('F1 Score',fontsize=fontsize-2)\n",
    "ax.set_xticks(np.arange(.2,len(f1_TiDHy)+.2))\n",
    "ax.set_xticklabels(['difficulty','slope','velocity'],fontsize=fontsize-2)\n",
    "ax.set_yticks(np.arange(0,1.1,.25))\n",
    "ax.set_yticklabels(np.arange(0,1.1,.25),fontsize=fontsize-2)\n",
    "ax.legend(['TiDHy','Obs.'],fontsize=fontsize,frameon=False,loc='upper right',bbox_to_anchor=(1.025,1.25),labelcolor='linecolor',handlelength=0,handleheight=0,ncols=2,columnspacing=.1)\n",
    "\n",
    "ax = axs[-1]\n",
    "acc_obs = accuracy_score(terrain_type_test.reshape(-1),state_compare[0])\n",
    "acc_TiDHy = accuracy_score(terrain_type_test.reshape(-1),state_compare[1])\n",
    "_,norm = map_discrete_cbar(cmap,len(np.unique(terrain_type_test)))\n",
    "im = ax.pcolormesh(state_compare[:,t:t+dt],cmap=cmap,norm=norm,alpha=.5,rasterized=True)\n",
    "# ax.set_xticks(np.arange(0,dt+3000,3000))\n",
    "# ax.set_xticklabels(np.arange(0,dt+3000,3000),fontsize=fontsize)\n",
    "ax.set_yticks(np.arange(.5,3,1))\n",
    "ax.set_yticklabels(['Obs. \\n {:02}%'.format(int(np.round(acc_obs*100))),'TiDHy \\n {:02}%'.format(int(np.round(acc_TiDHy*100))),'True'],fontsize=fontsize-2)\n",
    "ax.set_xlabel('timesteps',fontsize=fontsize)\n",
    "\n",
    "cbar = fig.colorbar(im,ax=axs[-1],aspect=10, pad=.05)\n",
    "cbar.set_ticks(np.arange(0,len(np.unique(terrain_type_test)),1))\n",
    "cbar.set_ticklabels([''.join(terrain_names[n]) for n in range(len(terrain_names))],fontsize=fontsize-2)\n",
    "cbar.outline.set_linewidth(1)\n",
    "cbar.minorticks_off()\n",
    "cbar.ax.tick_params(width=1,which=\"major\")\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2)\n",
    "\n",
    "fig.savefig(cfg.paths.fig_dir/'{}_Fig4.pdf'.format(nfig),dpi=300,transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8eed0f",
   "metadata": {},
   "source": [
    "# Load CalMS21 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "fontsize=13\n",
    "\n",
    "clrs = np.array(['#1A237E','#7E57C2','#757575','#BDBDBD','#4CAF50','#FF9800','#795548','#FF4081','#00BCD4','#FF1744','#FFFFFF','#000000'])\n",
    "sys_clrs = ['#E3A19F','#E3BE53','#708090','#90CCA9','#B7522E','#B0E0E6','#A89AC2','#556B2F','#FF6F61','#87CEEB','#FFDAB9','#40E0D0']\n",
    "cmap_sys = ListedColormap(sys_clrs)\n",
    "clr_ind =[2,2,8,8,9,9]\n",
    "# clr2 = [sys_clrs[clr_ind[n]] for n in range(len(clr_ind))]\n",
    "clr_ind3 = [2,8,9]\n",
    "clr2b = [sys_clrs[clr_ind3[n]] for n in range(len(clr_ind3))]\n",
    "\n",
    "clrs_b = clrs[[0,1,2,9,4,6,7,8,11]]\n",
    "cmap = ListedColormap(clrs)\n",
    "cmap_b = ListedColormap(clrs_b)\n",
    "cmap\n",
    "cmap_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CalMS21'\n",
    "base_dir = Path('/data/users/eabe/hypernets/{}/TiDHy_{}/'.format(dataset,dataset))\n",
    "configs = sorted(list(base_dir.rglob('*config.yaml'))[::2])\n",
    "\n",
    "for n,conf in enumerate(configs):\n",
    "    print(n,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5bd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "default_model_config = '/home/eabe/Research/MyRepos/HyperNets/conf/dataset/model/default_model.yaml'\n",
    "params = OmegaConf.load(default_model_config)\n",
    "cfg_path =configs[n]# Path('/data/users/eabe/hypernets/SLDS/DPC_SLDS/TestingNoTempLearning/mix_dim=15/config.yaml')\n",
    "cfg = OmegaConf.load(cfg_path)\n",
    "for k in cfg.paths.keys():\n",
    "    cfg.paths[k] = Path(cfg.paths[k])\n",
    "    cfg.paths[k].mkdir(parents=True, exist_ok=True)\n",
    "params_curr = cfg.dataset.model\n",
    "cfg.dataset.model = OmegaConf.merge(params, params_curr)\n",
    "# cfg.dataset.model['L1_inf_r2'] = 0\n",
    "# cfg.dataset.model['L1_inf_r'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ce630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.dataset.train.add_basic_features=False\n",
    "cfg.dataset.train.normalize=False\n",
    "data_dict, cfg = load_dataset(cfg)\n",
    "# ##### Convert to float tensors #####\n",
    "# test_inputs = torch.tensor(data_dict['inputs_test']).float()\n",
    "test_inputs = torch.tensor(data_dict['inputs_test']).float()\n",
    "\n",
    "input_dim = test_inputs.shape[-1]\n",
    "test_inputs = test_inputs.reshape(-1, cfg.train.sequence_length, input_dim)\n",
    "cfg.model.input_dim = input_dim\n",
    "\n",
    "print(f'Our inputs have shape: {test_inputs.shape}')\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_inputs)\n",
    "dataloader_test = torch.utils.data.DataLoader(test_dataset,batch_size=test_inputs.shape[0],pin_memory=True)\n",
    "device = torch.device(\"cuda:{}\".format(cfg.train['gpu']) if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de418971",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load weights and params #####\n",
    "rerecord = False\n",
    "epoch = 1000\n",
    "model = TiDHy.TiDHy(cfg.model, device, show_progress=cfg.train.show_progress).to(device)\n",
    "# set_seed(42)\n",
    "load_path = cfg.paths.ckpt_dir/'best.pth.tar'\n",
    "# load_path = sorted(list(cfg.paths.ckpt_dir.rglob('last_{}.pth.tar'.format(epoch))))[0]\n",
    "data_load = torch.load(load_path,map_location=device)\n",
    "model.load_state_dict(data_load['state_dict'])\n",
    "model.to(device)\n",
    "print('Loaded from {} epoch'.format(data_load['epoch']))\n",
    "epoch = data_load['epoch']\n",
    "\n",
    "\n",
    "# result_dict = load_results(model, dataloader_test, data_dict, device, cfg, epoch, rerecord=rerecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b20afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = [100,200,500,1000]\n",
    "\n",
    "cfg, result_dict = run_seq_len_model(seq_len, model, data_dict, device, epoch, cfg, rerun=False)\n",
    "\n",
    "data_dict, cfg = load_dataset(cfg)\n",
    "seq_len = sorted([int(el) for el in list(result_dict.keys())])\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "p = -1\n",
    "pca = PCA(n_components=3)\n",
    "full_state_z = data_dict['annotations_test']\n",
    "# reg_all = np.concatenate([R2_hat,W,R_bar],axis=1)\n",
    "X_pca = pca.fit_transform(result_dict['{}'.format(seq_len[p])]['R_hat'])\n",
    "n = 0\n",
    "t = 0; dt = len(X_pca)\n",
    "X_pca = X_pca[t:t+dt]\n",
    "comps = X_pca[full_state_z==n][t:t+dt]\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "# ax = Axes3D(fig)\n",
    "ax.scatter(comps[:,0],comps[:,1],comps[:,2],c='r',alpha=.75)\n",
    "ax.scatter(X_pca[:,0],X_pca[:,1],X_pca[:,2],c=clrs_b[p],alpha=.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "pio.renderers.default = \"notebook\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b18a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = -1\n",
    "pca = PCA(n_components=3)\n",
    "full_state_z = data_dict['annotations_test']\n",
    "# reg_all = np.concatenate([R2_hat,W,R_bar],axis=1)\n",
    "# X_pca = pca.fit_transform(result_dict['{}'.format(seq_len[p])]['R_hat'])\n",
    "X_pca = pca.fit_transform(result_dict['{}'.format(seq_len[p])]['R2_hat'])\n",
    "# X_pca = pca.fit_transform(R_hat)\n",
    "# X_pca = pca.fit_transform(R_bar)\n",
    "# X_pca = pca.fit_transform(reg_all)\n",
    "# X_pca = pca.fit_transform(W[:,np.sum(W,axis=0)!=0])\n",
    "# X_pca = pca.fit_transform(inputs_train)\n",
    "# X_pca = pca.fit_transform(b)\n",
    "# X_pca = pca.fit_transform(Vt.reshape(Vt.shape[0],-1))\n",
    "n = 3\n",
    "t = 0; dt = len(X_pca)\n",
    "fig = go.Figure()\n",
    "comps = X_pca[full_state_z==n][t:t+dt]\n",
    "# labels = full_state_z[full_state_z==n]\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=X_pca[:,0], y=X_pca[:,1], z=X_pca[:,2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=1,\n",
    "            color='black',                # set color to an array/list of desired values\n",
    "            colorscale='Viridis',   # choose a colorscale\n",
    "            opacity=.1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=comps[:,0], y=comps[:,1], z=comps[:,2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color='red',                # set color to an array/list of desired values\n",
    "            colorscale='Viridis',   # choose a colorscale\n",
    "            opacity=.01\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    width=500,\n",
    "    height=500,\n",
    "    autosize=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ab3cf",
   "metadata": {},
   "source": [
    "## Record Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88393e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = False\n",
    "ts=1\n",
    "W = result_dict['{}'.format(seq_len[ts])]['W'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['W'].shape[-1])\n",
    "# b = result_dict['{}'.format(seq_len[ts])]['b'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['b'].shape[-1])\n",
    "I = result_dict['{}'.format(seq_len[ts])]['I'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I'].shape[-1])\n",
    "Ihat = result_dict['{}'.format(seq_len[ts])]['I_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I_hat'].shape[-1])\n",
    "R_hat = result_dict['{}'.format(seq_len[ts])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_hat'].shape[-1])\n",
    "R_bar = result_dict['{}'.format(seq_len[ts])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_bar'].shape[-1])\n",
    "R2_hat = result_dict['{}'.format(seq_len[ts])]['R2_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R2_hat'].shape[-1])\n",
    "Ut = result_dict['{}'.format(seq_len[ts])]['Ut'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['Ut'].shape[-2],result_dict['{}'.format(seq_len[ts])]['Ut'].shape[-1])\n",
    "##### Plot dynamic matrices #####\n",
    "if cfg.model.low_rank_temp:\n",
    "    Uk = torch.bmm(model.temporal.unsqueeze(-1),model.temporal.unsqueeze(1)).data.cpu().detach()\n",
    "else:\n",
    "    Uk = model.temporal.data.cpu().detach().reshape(model.mix_dim,model.r_dim,model.r_dim)\n",
    "full_state_z = data_dict['annotations_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25508806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "reg_variables = [np.concatenate([R2_hat,W,R_hat],axis=-1),R2_hat,W,R_hat,R_bar,I]\n",
    "labels = ['all','R2_hat','W','R_hat','R_bar','I']\n",
    "\n",
    "# reg_variables = W\n",
    "max_acc = 0\n",
    "tr_batch_size = 40\n",
    "batch_size = 10\n",
    "for k,reg_vars in enumerate(reg_variables):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(reg_vars.reshape(-1,reg_vars.shape[-1]), full_state_z.reshape(-1), test_size=0.25, random_state=42)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(reg_vars.reshape(-1,reg_vars.shape[-1]), terrain.reshape(-1), test_size=0.25, random_state=42)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    scores = neigh.score(X_test, y_test)\n",
    "    print(labels[k],scores)\n",
    "    if (scores > max_acc) & (labels[k] != 'I'):\n",
    "        y_pred = neigh.predict(reg_vars.reshape(-1,reg_vars.shape[-1]))\n",
    "        max_acc = scores\n",
    "        best_reg_vars = reg_vars\n",
    "        best_label = labels[k]\n",
    "        best_pred = y_pred\n",
    "    else:\n",
    "        I_pred = neigh.predict(reg_vars.reshape(-1,reg_vars.shape[-1]))\n",
    "\n",
    "# plt.imshow(confusion_matrix(full_state_z, best_pred),cmap='viridis')\n",
    "# plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d15570",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=13\n",
    "fps = 30\n",
    "fig = plt.figure(constrained_layout=True, figsize=(7.75,5.5))\n",
    "gs  = gridspec.GridSpec(nrows=8, ncols=4,hspace=10,wspace=.5) \n",
    "gs0 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=gs[:3,:],  wspace=.5,hspace=.2)\n",
    "# gsb = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=gs[:3,2:3], wspace=.1,hspace=.5)\n",
    "\n",
    "# gsc = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=gs[:5,3:], wspace=.5,hspace=.1)\n",
    "gs1 = gridspec.GridSpecFromSubplotSpec(1, 4, subplot_spec=gs[3:6,:], wspace=.2,hspace=.1)\n",
    "\n",
    "gs2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=gs[6:,:-1],   wspace=0, hspace=.10)\n",
    "\n",
    "##### plotting video frame ######\n",
    "t = 50; dt = 1\n",
    "skeleton = np.array([[0,1],[0,2],[2,3],[1,3],[3,4],[3,5],[4,6],[5,6]])\n",
    "ani1_x = data_dict['inputs_train'][t:t+dt,:7]\n",
    "ani1_y = data_dict['inputs_train'][t:t+dt,7:14]\n",
    "ani2_x = data_dict['inputs_train'][t:t+dt,14:21]\n",
    "ani2_y = data_dict['inputs_train'][t:t+dt,21:28]\n",
    "I1_x = Ihat[t:t+dt,:7]\n",
    "I1_y = Ihat[t:t+dt,7:14]\n",
    "I2_x = Ihat[t:t+dt,14:21]\n",
    "I2_y = Ihat[t:t+dt,21:28]\n",
    "labels = data_dict['annotations_train'][t:t+dt]\n",
    "clrs = plt.get_cmap('tab10',4)\n",
    "axs = np.array([fig.add_subplot(gs0[:2])])\n",
    "ax = axs[0]\n",
    "# ax.imshow(frames[t]) ##### Load frames from video in cell below\n",
    "for n in range(7):\n",
    "    im = ax.scatter(ani1_x[:,n],ani1_y[:,n],s=10,c='#ffa600ff')\n",
    "    im = ax.scatter(ani2_x[:,n],ani2_y[:,n],s=10,c='#4daf50ff')\n",
    "tt=0\n",
    "for n in range(len(skeleton)):\n",
    "    ax.plot(ani1_x[:,skeleton[n]].squeeze(),ani1_y[:,skeleton[n]].squeeze(),'#ffa600ff',lw=2,zorder=1)\n",
    "    ax.plot(ani2_x[:,skeleton[n]].squeeze(),ani2_y[:,skeleton[n]].squeeze(),'#4daf50ff',lw=2,zorder=1)\n",
    "ax.axis('off')\n",
    "\n",
    "###### Plotting Observations #####\n",
    "axs = np.array([fig.add_subplot(gs0[2])])\n",
    "ax = axs[0]\n",
    "spacing = .75; fontsize=13\n",
    "t = 0; dt = 10000\n",
    "hlines,hlines_Ihat= [],[]\n",
    "for n in range(I.shape[-1]):\n",
    "    mean_centered = I[t:t+dt,n] - np.mean(I[t:t+dt,n],axis=0)\n",
    "    mean_centered = mean_centered\n",
    "    ax.plot(1/fps*np.arange(0,dt,1),mean_centered + n/spacing,color='k', lw=1)\n",
    "    hlines.append(np.mean(mean_centered + n/spacing,axis=0))\n",
    "    mean_centered_Ihat = Ihat[t:t+dt,n] - np.mean(Ihat[t:t+dt,n],axis=0)\n",
    "    ax.plot(1/fps*np.arange(0,dt,1),mean_centered_Ihat + n/spacing,ls='--',color='r', lw=1,zorder=2,label='Pred')\n",
    "    hlines_Ihat.append(np.mean(mean_centered_Ihat + n/spacing,axis=0))\n",
    "\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2, pad=0)\n",
    "ax.set_xlabel('time (s)',fontsize=fontsize)\n",
    "ax.set_ylabel(\"observations\",fontsize=fontsize)\n",
    "ax.set_yticks([])\n",
    "\n",
    "##### Timescales #####\n",
    "axs = np.array([fig.add_subplot(gs0[3])])\n",
    "ax = axs[0]\n",
    "dts = 1/len(seq_len)\n",
    "y_ranges = np.arange(0,1,(dts*dts)).reshape(-1,len(seq_len))[:,(0,-1)]\n",
    "for ts in range(len(seq_len)):\n",
    "    R_bar = result_dict['{}'.format(seq_len[ts])]['R_bar'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_bar'].shape[-1])\n",
    "    R_hat = result_dict['{}'.format(seq_len[ts])]['R_hat'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['R_hat'].shape[-1])\n",
    "    I = result_dict['{}'.format(seq_len[ts])]['I'].reshape(-1,result_dict['{}'.format(seq_len[ts])]['I'].shape[-1])\n",
    "\n",
    "    # ##### Plottign Eigenvalues #####\n",
    "    Uhat_all = []\n",
    "    for state in range(len(np.unique(full_state_z))):\n",
    "        rhat2 = R_hat[np.where(full_state_z==state)[0],:]\n",
    "        Uhat_0 = np.linalg.inv(rhat2[:-1].T@rhat2[:-1])@rhat2[:-1].T@rhat2[1:]\n",
    "        Uhat_all.append(Uhat_0)\n",
    "        \n",
    "    Uhat_all = np.stack(Uhat_all)\n",
    "    evals_Uhat_all = np.linalg.eigvals(Uhat_all).reshape(-1)\n",
    "    timescales = np.real(np.log(evals_Uhat_all))/fps\n",
    "\n",
    "    ax.scatter(x=1/np.abs(timescales),y=np.abs(evals_Uhat_all)+ts,c=clrs_b[ts],alpha=.5,edgecolor='None',s=25)\n",
    "\n",
    "for ts in range(len(seq_len)):\n",
    "    ax.axhline(y=ts,c=clrs_b[ts],linestyle='--',zorder=-1)\n",
    "#     ax.axvline(x=timescales_M[n],c=sys_clrs[n])\n",
    "ax.set_yticks([1/2 + q for q in range(len(seq_len))])\n",
    "ax.set_yticklabels(seq_len,fontsize=fontsize-2)\n",
    "ax.set_ylabel('T',fontsize=fontsize,labelpad=-5)\n",
    "# ax.spines.left.set_visible(False)\n",
    "ax.set_xscale('symlog',linthresh=100)\n",
    "ax.set_xlabel('timescales',fontsize=fontsize,labelpad=0)\n",
    "ax.set_xticks([10e0,10e1,10e2,10e3,10e4,10e5])\n",
    "ax.tick_params(axis='x', labelsize=fontsize-2, pad=0)\n",
    "ax.set_xlim([-1,7e4])\n",
    "\n",
    "###### PCA #####\n",
    "n = 0; m = 1\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(R_bar.reshape(-1,R_hat.shape[-1]))\n",
    "lst = list(itertools.combinations(np.arange(X_pca.shape[-1]), 2))\n",
    "unq = set(lst)\n",
    "axs = np.array([fig.add_subplot(gs1[n]) for n in range(4)])\n",
    "for state in range(4):\n",
    "    ax = axs[state]\n",
    "    comps = X_pca[full_state_z==state]\n",
    "    comps = comps/np.max(np.abs(comps),axis=0)\n",
    "    # comps = X_pca[(full_state_z==0) | (full_state_z==1) | (full_state_z==2)]\n",
    "    h,xedge,yedge = np.histogram2d(comps[:,n],comps[:,m],bins=50,range=[[-1,1],[-1,1]],density=True)\n",
    "    im = ax.imshow((h).T,cmap='turbo',extent=[xedge[0],xedge[-1],yedge[0],yedge[-1]],alpha=1)\n",
    "    ax.axis('square')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.set_title('{}'.format(list(data_dict['vocabulary'].keys())[state]),fontsize=fontsize,y=.95)\n",
    "    ax.set_xlabel('PC{}'.format(n+1),fontsize=fontsize)\n",
    "    if (state==0):\n",
    "        ax.set_ylabel('PC{}'.format(m+1),fontsize=fontsize)\n",
    "ax = axs[-1]\n",
    "cbar = fig.colorbar(im,ax=axs.flatten(),aspect=10,shrink=.5)\n",
    "cbar.set_ticks([0,np.max(h)])\n",
    "cbar.set_ticklabels(['low','high'],rotation=90)\n",
    "cbar.outline.set_linewidth(1)\n",
    "cbar.minorticks_off()\n",
    "cbar.ax.tick_params(width=1,which=\"major\")\n",
    "\n",
    "\n",
    "##### Behaviroal State ID #####\n",
    "t = 80000; dt = 10000; \n",
    "acc_TiDHy=accuracy_score(best_pred, full_state_z)\n",
    "# acc_TiDHy=neigh.score(I_pred, full_state_z)\n",
    "state_compare = np.stack([y_pred,full_state_z],axis=0)\n",
    "_,norm = map_discrete_cbar(cmap,len(np.unique(full_state_z)))\n",
    "axs = np.array([fig.add_subplot(gs2[n]) for n in range(1)])\n",
    "ax = axs[0]\n",
    "im = ax.pcolormesh(state_compare[:,t:t+dt],cmap=cmap,norm=norm,alpha=.5,rasterized=True)\n",
    "ax.set_yticks(np.arange(.5,2,1))\n",
    "ax.set_yticklabels(['TiDHy \\n {:02}%'.format(int(np.round(acc_TiDHy*100))),'True'],fontsize=fontsize)\n",
    "ax.set_xticks(np.arange(0,dt,60*fps))\n",
    "ax.set_xticklabels((np.arange(0,dt,60*fps)*1/fps).astype(int),fontsize=fontsize-2)\n",
    "ax.set_xlabel('time (s)',fontsize=fontsize)\n",
    "\n",
    "# plt.tight_layout()\n",
    "cbar = fig.colorbar(im,ax=axs.flatten(),aspect=10, pad=.01)\n",
    "\n",
    "cbar.set_ticks(np.arange(0,len(np.unique(full_state_z)),1))\n",
    "cbar.set_ticklabels(list(data_dict['vocabulary'].keys()),fontsize=fontsize)\n",
    "cbar.outline.set_linewidth(1)\n",
    "cbar.minorticks_off()\n",
    "cbar.ax.tick_params(width=1,which=\"major\")\n",
    "\n",
    "# fig.savefig(cfg.paths.fig_dir / 'Fig5.pdf',dpi=300,transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e262598",
   "metadata": {},
   "source": [
    "### Load video frames for CalMS21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    " \n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('/data/users/eabe/hypernets/CalMS21/datasets/mouse001_task1_annotator1.mp4')\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    " \n",
    "# Read until video is completed\n",
    "frames = []\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = cap.read()\n",
    "  if ret == True:\n",
    "    frames.append(frame)   \n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    " \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41097339",
   "metadata": {},
   "source": [
    "## Animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41097339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "import cv2\n",
    "import gc\n",
    "mpl.use('agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def make_plt_im(t, X_pca,data_dict,full_state_z):   #\n",
    "    trail = 5\n",
    "    labels = full_state_z[t-trail:t+1]\n",
    "    cmap = plt.get_cmap('tab10',len(np.unique(full_state_z)))\n",
    "    bounds = np.arange(len(np.unique(full_state_z))+1)\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    fig,axs = plt.subplots(1,3,figsize=(15,5))\n",
    "    ax = axs[0]\n",
    "    im = ax.scatter(X_pca[:,0],X_pca[:,1],s=1,c='k',alpha=.01)\n",
    "    im = ax.scatter(X_pca[t-trail:t+1,0],X_pca[t-trail:t+1,1],s=3,c=labels,cmap=cmap,norm=norm,alpha=1)\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([-1,1])\n",
    "    ax.set_ylim([-1,1])\n",
    "    cbar = fig.colorbar(im, ax=axs,location='right')\n",
    "    cbar.set_ticks(np.arange(.5,len(np.unique(full_state_z)),1))\n",
    "    cbar.set_ticklabels(np.arange(-1,len(np.unique(full_state_z))-1,1))\n",
    "    ax.set_title('Rbar PCA comps')\n",
    "\n",
    "\n",
    "    ani1_x = data_dict['inputs_test'][t-trail:t+1,:7]\n",
    "    ani1_y = data_dict['inputs_test'][t-trail:t+1,7:14]\n",
    "    ani2_x = data_dict['inputs_test'][t-trail:t+1,14:21]\n",
    "    ani2_y = data_dict['inputs_test'][t-trail:t+1,21:28]\n",
    "    labels = data_dict['annotations_test'][t-trail:t+1]\n",
    "    for n in range(7):\n",
    "        ax = axs[1]\n",
    "        im = ax.scatter(ani1_x[:,n],ani1_y[:,n],s=1,c=labels,cmap=cmap,norm=norm,)\n",
    "        ax.axis('square')\n",
    "        ax.set_xlim([0,1])\n",
    "        ax.set_ylim([0,1])\n",
    "        ax.set_title('Mouse 1')\n",
    "        ax = axs[2]\n",
    "        ax.scatter(ani2_x[:,n],ani2_y[:,n],s=1,c=labels,cmap=cmap,norm=norm,)\n",
    "        ax.axis('square')\n",
    "        ax.set_xlim([0,1])\n",
    "        ax.set_ylim([0,1])\n",
    "        ax.set_title('Mouse 2')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "    fig.canvas.draw()       # draw the canvas, cache the renderer\n",
    "    images = np.frombuffer(fig.canvas.tostring_rgb(),\n",
    "                        dtype='uint8').reshape(int(height), int(width), 3)\n",
    "    plt.close()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = make_plt_im(t, X_pca,data_dict)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# full_state_z = data_dict['annotations_test']\n",
    "full_state_z = cluster_labels\n",
    "X_pca = pca.fit_transform(R_bar)\n",
    "\n",
    "t = 80000; dt = 5000\n",
    "trail = 5\n",
    "labels = full_state_z[t-trail:t+1]\n",
    "cmap = plt.get_cmap('tab10',len(np.unique(full_state_z)))\n",
    "bounds = np.arange(len(np.unique(full_state_z))+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig,axs = plt.subplots(1,3,figsize=(15,5))\n",
    "ax = axs[0]\n",
    "im = ax.scatter(X_pca[:,0],X_pca[:,1],s=1,c='k',alpha=.01)\n",
    "im = ax.scatter(X_pca[t-trail:t+1,0],X_pca[t-trail:t+1,1],s=3,c=labels,cmap=cmap,norm=norm,alpha=1)\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-1,1])\n",
    "ax.set_ylim([-1,1])\n",
    "cbar = fig.colorbar(im, ax=axs,location='right')\n",
    "cbar.set_ticks(np.arange(.5,len(np.unique(full_state_z)),1))\n",
    "cbar.set_ticklabels(np.arange(-1,len(np.unique(full_state_z))-1,1))\n",
    "ax.set_title('Rbar PCA comps')\n",
    "\n",
    "\n",
    "ani1_x = data_dict['inputs_test'][t-trail:t+1,:7]\n",
    "ani1_y = data_dict['inputs_test'][t-trail:t+1,7:14]\n",
    "ani2_x = data_dict['inputs_test'][t-trail:t+1,14:21]\n",
    "ani2_y = data_dict['inputs_test'][t-trail:t+1,21:28]\n",
    "labels = data_dict['annotations_test'][t-trail:t+1]\n",
    "for n in range(7):\n",
    "    ax = axs[1]\n",
    "    im = ax.scatter(ani1_x[:,n],ani1_y[:,n],s=1,c=labels,cmap=cmap,norm=norm,)\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_title('Mouse 1')\n",
    "    ax = axs[2]\n",
    "    ax.scatter(ani2_x[:,n],ani2_y[:,n],s=1,c=labels,cmap=cmap,norm=norm,)\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_title('Mouse 2')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.savefig(cfg.paths.fig_dir/'test.png',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(cluster_labels==2)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "##### initialize time points for animation and progressbar #####\n",
    "t = 0 ; dt = 10000\n",
    "full_state_z = cluster_labels\n",
    "state = 'I'\n",
    "time_range = np.arange(t,t+dt)#  np.where(cluster_labels==state)[0]#\n",
    "num_ticks = np.size(time_range)\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(I)\n",
    "\n",
    "##### Put large arrays into shared memory #####\n",
    "X_pca_r = ray.put(X_pca)\n",
    "data_dict_r = ray.put(data_dict)\n",
    "full_state_z_r = ray.put(full_state_z)\n",
    "##### Loop over parameters appending process ids #####\n",
    "result_ids = []\n",
    "for t in time_range:\n",
    "    result_ids.append(make_plt_im.remote(t, X_pca_r, data_dict_r,full_state_z_r))\n",
    "\n",
    "##### pring progressbar and get results #####\n",
    "results_p = ray.get(result_ids)\n",
    "images = np.stack([results_p[i] for i in range(len(results_p))])\n",
    "\n",
    "##### Make video with opencv #####\n",
    "aniname = 'PCA_Evolve_{}.mp4'.format(state) \n",
    "\n",
    "\n",
    "vid_name = cfg.paths.fig_dir / aniname\n",
    "FPS = 30\n",
    "out = cv2.VideoWriter(vid_name.as_posix(), cv2.VideoWriter_fourcc(*'mp4v'), FPS, (images.shape[-2], images.shape[-3]))\n",
    "\n",
    "for fm in tqdm(range(images.shape[0])):\n",
    "    out.write(cv2.cvtColor(images[fm], cv2.COLOR_BGR2RGB))\n",
    "out.release()\n",
    "print('Making Animation {}: {}'.format(aniname, time.time()-start))\n",
    "del results_p, X_pca_r, data_dict_r, full_state_z_r\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 80000 ; dt = 5000\n",
    "labels = full_state_z[t:t+dt]\n",
    "cmap = plt.get_cmap('tab10',len(np.unique(full_state_z)))\n",
    "bounds = np.arange(len(np.unique(full_state_z))+1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig,axs = plt.subplots(1,3,figsize=(15,5))\n",
    "ax = axs[0]\n",
    "im = ax.scatter(X_pca[t:t+dt,0],X_pca[t:t+dt,1],s=1,c=labels,cmap=cmap,norm=norm,alpha=1)\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-1,1])\n",
    "ax.set_ylim([-1,1])\n",
    "cbar = fig.colorbar(im, ax=axs,location='right')\n",
    "cbar.set_ticks(np.arange(.5,4,1))\n",
    "cbar.set_ticklabels(list(data_dict['vocabulary'].keys()))\n",
    "ax.set_title('Rbar PCA comps')\n",
    "\n",
    "\n",
    "ani1_x = data_dict['inputs_test'][t:t+dt,:7]\n",
    "ani1_y = data_dict['inputs_test'][t:t+dt,7:14]\n",
    "ani2_x = data_dict['inputs_test'][t:t+dt,14:21]\n",
    "ani2_y = data_dict['inputs_test'][t:t+dt,21:28]\n",
    "labels = data_dict['annotations_test'][t:t+dt]\n",
    "clrs = plt.get_cmap('tab10',4)\n",
    "for n in range(7):\n",
    "    ax = axs[1]\n",
    "    im = ax.scatter(ani1_x[:,n],ani1_y[:,n],s=1,c=labels,cmap=clrs)\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.axis('square')\n",
    "    ax.set_title('Mouse 1')\n",
    "    ax = axs[2]\n",
    "    ax.scatter(ani2_x[:,n],ani2_y[:,n],s=1,c=labels,cmap=clrs)\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.set_title('Mouse 2')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TiDHy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
