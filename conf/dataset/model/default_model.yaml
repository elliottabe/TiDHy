batch_size: 2048
input_dim: 6
r2_dim: ${resolve_default:5,${...r2_dim}}
r_dim: ${resolve_default:10,${...r_dim}}
mix_dim: ${resolve_default:15,${...mix_dim}}
hyper_hid_dim: 50
max_iter: 2000
loss_type: MSE
dyn_bias: false
nonlin_decoder: false
##### Learning rate params #####
lr_r: .2
lr_r2: .2
learning_rate_gamma: 0.5
learning_rate_s: 0.01
learning_rate_t: 0.01
learning_rate_h: 0.001
lr_weights: 0.01
lr_weights_inf: 0.005
##### Optimization params #####
normalize_temporal: false
normalize_spatial: false
stateful: false
temp_weight: 2
spat_weight: .5
tol: 0.01
use_r2_decoder: false
r2_decoder_hid_dim: 50
low_rank_temp: false
##### Gradient norm params #####
grad_norm: true
grad_norm_inf: false
grad_alpha: .5
grad_alpha_inf: 1
##### Regularization params #####
Lnuc_alpha: ${resolve_default:0,${...Lnuc_alpha}}
L0_alpha: ${resolve_default:0,${...L0_alpha}}
L1_alpha: ${resolve_default:0,${...L1_alpha}}
L1_alpha_spat: ${resolve_default:0,${...L1_alpha_spat}}
L1_alpha_inf: ${resolve_default:0,${...L1_alpha_inf}}
L1_alpha_W: ${resolve_default:0,${...L1_alpha_W}}
Orth_alpha_spat: ${resolve_default:0,${...Orth_alpha_spat}}
L1_alpha_r2: 0
L1_inf_w: 0
L1_inf_r: 0
L1_inf_r2: 0
lmda_r: 0
lmda_r2: 0
cos_eta: 5
clip_grad: 500
weight_decay: 0.00001
batch_converge: True